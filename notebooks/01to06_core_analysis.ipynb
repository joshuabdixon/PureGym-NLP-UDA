{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf409e7",
   "metadata": {},
   "source": [
    "# 01to06_core_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67214f38",
   "metadata": {},
   "source": [
    "#### Hardware and runtime\n",
    "\n",
    "All experiments were run locally on a MacBook Pro (16-inch, November 2024) with an Apple M4 Pro chip (14 CPU cores: 10 performance and 4 efficiency cores) and 24 GB unified memory, running macOS Tahoe 26.2. All steps were executed on CPU, and no distributed computing frameworks (for example SLURM or OpenPBS) were used.\n",
    "\n",
    "**Runtime:** On the hardware above, the notebook completes in approximately **5 minutes**. Runtime may vary slightly depending on installed package versions and whether optional diagnostics are enabled.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c15718",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "| Section | Description |\n",
    "|---|---|\n",
    "| 01_preprocessing | Filters UK Trustpilot reviews by country, date range, and language using `TrustpilotDataFilter` and `detect_language` (defined in this notebook), then applies `TextPreprocessor` (imported from `utils.processing.text_preprocessor`) to generate modelling-ready text. |\n",
    "| 02_eda_and_split_negative_review_data | Produces word-frequency tables and word clouds for all, negative, and non-negative reviews using `Plotter` (defined in this notebook), then splits the dataset into negative vs non-negative using the configured rating thresholds. |\n",
    "| 03_topic_modelling_bertopic | Runs BERTopic on negative reviews via `BERTopicRunner` (imported from `modelling.bertopic.bertopic_runner`), using configured UMAP settings and saving topic tables and plots for reporting. |\n",
    "| 04a_emotion_analysis_roberta | Performs transformer emotion classification (DistilRoBERTa) using `Initialiser`, `EmotionParams`, and `EmotionModelDataCompiler` (all defined in this notebook), plus `bar_plot` (defined in this notebook) for emotion distribution plots. |\n",
    "| 04b_emotion_analysis_bert_base_uncased | Repeats the same emotion pipeline for comparison using the second model in `EmotionParams` (defined in this notebook), reusing `Initialiser`, `EmotionModelDataCompiler`, and `bar_plot` (all defined in this notebook). |\n",
    "| 05_topic_modelling_bertopic_per_emotion_neg_reviews | Runs BERTopic per emotion on negative reviews (for example sadness) using `BERTopicRunner` (imported), enforcing a minimum document threshold and exporting topic summaries and visualisations. |\n",
    "| 06_topic_modelling_lda_gensim | Trains and evaluates Gensim LDA baselines and exports pyLDAvis artefacts using the in-notebook pipeline `LDAConfig`, `LDARunner`, `LDAEvaluator`, `PreprocessedTokeniser`, `GensimCorpusBuilder`, and `run_emotion_subset` (all defined in this notebook). |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b3f1d1",
   "metadata": {},
   "source": [
    "**Reproducibility note (BERTopic plots and top topics)**  \n",
    "\n",
    "* BERTopic visualisations in this notebook (for example intertopic distance maps) rely on a UMAP projection. UMAP can yield slightly different embeddings across hardware/OS and execution settings (particularly when parallelism differs), so plots generated on a different device from the one specified above may not exactly match the reported figures even when the same random seed is used. On the device used for this project, the plots are reproducible for the fixed seed (**901**).\n",
    "\n",
    "* This sensitivity to execution environment is one reason LDA was also explored in this project, as a complementary topic modelling approach with more straightforward reproducibility characteristics.\n",
    "\n",
    "* Documentation: https://umap-learn.readthedocs.io/en/latest/reproducibility.html\n",
    "\n",
    "* The reported plots are pre-saved in the folders for this reason. However, executing all notebooks will overwrite them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70999bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import ast\n",
    "from configparser import ConfigParser\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "# Resolve project root as the parent of the folder the notebook is currently in\n",
    "CWD = Path.cwd().resolve()\n",
    "PROJECT_ROOT = CWD.parent\n",
    "\n",
    "# Safety fallback\n",
    "if not (PROJECT_ROOT / \"config.ini\").exists():\n",
    "    PROJECT_ROOT = next((p for p in (CWD, *CWD.parents) if (p / \"config.ini\").exists()), None)\n",
    "    if PROJECT_ROOT is None:\n",
    "        raise FileNotFoundError(\"Could not locate 'config.ini' in the current directory or its parents.\")\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "CONFIG = ConfigParser()\n",
    "CONFIG.read(PROJECT_ROOT / \"config.ini\")\n",
    "\n",
    "print(\"CONFIG used:\")\n",
    "for section in CONFIG.sections():\n",
    "    print(f\"\\n[{section}]\")\n",
    "    for key, value in CONFIG[section].items():\n",
    "        print(f\"{key} = {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6738bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = CONFIG[\"REPRODUCIBILITY\"].getint(\"SEED\")\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe31987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "NOTEBOOK_T0_GLOBAL = time.perf_counter()\n",
    "print(\"Notebook timer started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db5dd4",
   "metadata": {},
   "source": [
    "# 01_preprocessing\n",
    "\n",
    "This section performs all preprocessing required prior to modelling and analysis:\n",
    "\n",
    "- Filters the raw Trustpilot dataset by country (UK), date range, language, and selected variables.\n",
    "\n",
    "- Applies text preprocessing (normalisation, contraction handling, lemmatisation, punctuation and digit removal, stopword filtering).\n",
    "\n",
    "- Produces separate preprocessed datasets for topic modelling and for sentiment or emotion analysis.\n",
    "\n",
    "**Outputs (data/):**\n",
    "\n",
    "- `PureGym Customer Reviews_raw_filtered.csv`\n",
    "\n",
    "- `PureGym Customer Reviews_preprocessed.csv`\n",
    "\n",
    "- `PureGym Customer Reviews_preprocessed_sentiment.csv`\n",
    "\n",
    "**Compute and reproducibility:**\n",
    "\n",
    "- Local run on MacBook Pro (16-inch, Nov 2024), Apple M4 Pro (14 CPU cores), 24 GB unified memory, macOS Tahoe 26.2.\n",
    "\n",
    "- CPU-only execution, no distributed frameworks.\n",
    "\n",
    "- Fixed random seed: **901**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_T0 = time.perf_counter()\n",
    "print(\"Section timer started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e57f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Optional, Callable\n",
    "\n",
    "from utils.data_management.data_io import load_csv, save_csv\n",
    "from utils.processing.text_preprocessor import TextPreprocessor\n",
    "\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf0895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTERING\n",
    "SELECTED_COLS = ast.literal_eval(CONFIG[\"FILTERING\"][\"SELECTED_COLS\"])\n",
    "\n",
    "COUNTRY_CODE = CONFIG[\"FILTERING\"][\"COUNTRY_CODE\"]\n",
    "TEXT_COL = CONFIG[\"FILTERING\"][\"TEXT_COL\"]\n",
    "DETECT_LANGUAGE = CONFIG[\"FILTERING\"][\"DETECT_LANGUAGE\"]\n",
    "\n",
    "# ANALYSIS DATES\n",
    "DATE_COL = CONFIG[\"ANALYSIS_DATES\"][\"DATE_COL\"]\n",
    "START_DATE = CONFIG[\"ANALYSIS_DATES\"][\"START_DATE\"]\n",
    "END_DATE = CONFIG[\"ANALYSIS_DATES\"][\"END_DATE\"]\n",
    "\n",
    "# REPRODUCIBILITY\n",
    "DetectorFactory.seed = SEED  # Configure langdetect RNG once\n",
    "\n",
    "# DATA\n",
    "DATA_DIR = (PROJECT_ROOT / CONFIG[\"DATA\"][\"DATA_DIR\"]).resolve()\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_FILENAME = CONFIG[\"DATA\"][\"RAW_FILENAME\"]\n",
    "RAW_PATH = f\"{DATA_DIR}/{RAW_FILENAME}\"\n",
    "\n",
    "# PREPROCESSING \n",
    "STOPWORD_LANGUAGE = \"english\"\n",
    "EXTRA_STOPWORDS = [\"pure\", \"gym\", \"puregym\", \"equipment\"]\n",
    "\n",
    "PUNCTUATION_PATTERN_TOPIC = r\"[-.,\\\"'’`;:!?()/&%]+\"\n",
    "USE_POS_TAGGING_TOPIC = False\n",
    "\n",
    "PUNCTUATION_PATTERN_SENTIMENT = r\"[-.,\\\"'’`;:()/&%]+\"\n",
    "USE_POS_TAGGING_SENTIMENT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e78cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text: Optional[str]) -> str:\n",
    "    \"\"\"\n",
    "    Detect the language of a text string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str or None\n",
    "        Input text.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        ISO 639-1 language code or ``\"unknown\"`` if detection fails.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"unknown\"\n",
    "\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa96259",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrustpilotDataFilter:\n",
    "    \"\"\"\n",
    "    Apply standardised filtering operations to Trustpilot review data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    selected_columns : list[str]\n",
    "        Columns to retain in the final output DataFrame.\n",
    "    date_column : str\n",
    "        Name of the column containing review dates.\n",
    "    start_date : str or pandas.Timestamp\n",
    "        Inclusive start date for filtering.\n",
    "    end_date : str or pandas.Timestamp\n",
    "        Inclusive end date for filtering.\n",
    "    country_code : str or None, optional\n",
    "        Country code to filter on. If ``None``, no country filtering is applied.\n",
    "    language_detector : Callable[[str | None], str], optional\n",
    "        Function used to detect language from text.\n",
    "    text_column : str\n",
    "        Column used for language detection.\n",
    "    allowed_languages : Iterable[str] or None, optional\n",
    "        Languages to retain. If ``None``, no language filtering is applied.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        selected_columns: list[str],\n",
    "        date_column: str,\n",
    "        start_date,\n",
    "        end_date,\n",
    "        country_code: Optional[str] = None,\n",
    "        language_detector: Callable[[Optional[str]], str] = detect_language,\n",
    "        text_column: str = \"Review\",\n",
    "        allowed_languages: Optional[Iterable[str]] = (\"en\",),\n",
    "    ) -> None:\n",
    "        self.selected_columns = selected_columns\n",
    "        self.date_column = date_column\n",
    "        self.start_date = pd.Timestamp(start_date)\n",
    "        self.end_date = pd.Timestamp(end_date)\n",
    "        self.country_code = country_code\n",
    "        self.language_detector = language_detector\n",
    "        self.text_column = text_column\n",
    "        self.allowed_languages = allowed_languages\n",
    "\n",
    "    def apply(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply all configured filters to the dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas.DataFrame\n",
    "            Raw Trustpilot dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            Filtered dataset containing only the selected columns.\n",
    "        \"\"\"\n",
    "        df_filtered = df.copy()\n",
    "\n",
    "        df_filtered = self._filter_country(df_filtered)\n",
    "        df_filtered = self._parse_dates(df_filtered)\n",
    "        df_filtered = self._filter_date_range(df_filtered)\n",
    "        df_filtered = self._filter_language(df_filtered)\n",
    "        df_filtered = self._select_columns(df_filtered)\n",
    "\n",
    "        return df_filtered\n",
    "\n",
    "    def _filter_country(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Filter reviews by country code.\n",
    "        \"\"\"\n",
    "        if self.country_code is None:\n",
    "            return df\n",
    "\n",
    "        return df[df[\"Country Code\"] == self.country_code]\n",
    "\n",
    "    def _parse_dates(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Parse the date column into pandas datetime format.\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "        df[self.date_column] = pd.to_datetime(df[self.date_column], errors=\"coerce\")\n",
    "        return df\n",
    "\n",
    "    def _filter_date_range(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Filter reviews within the specified date range.\n",
    "        \"\"\"\n",
    "        mask = (\n",
    "            (df[self.date_column] >= self.start_date) &\n",
    "            (df[self.date_column] <= self.end_date)\n",
    "        )\n",
    "        return df[mask]\n",
    "\n",
    "    def _filter_language(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Filter reviews by detected language.\n",
    "        Language detection is performed temporarily and the helper\n",
    "        column is dropped before returning the dataset.\n",
    "        \"\"\"\n",
    "        if self.allowed_languages is None:\n",
    "            return df\n",
    "\n",
    "        df = df.copy()\n",
    "        df[\"_detected_language\"] = df[self.text_column].apply(self.language_detector)\n",
    "\n",
    "        df = df[df[\"_detected_language\"].isin(self.allowed_languages)]\n",
    "        df = df.drop(columns=\"_detected_language\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _select_columns(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Select the final output columns.\n",
    "        \"\"\"\n",
    "        return df[self.selected_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d951b22b",
   "metadata": {},
   "source": [
    "### Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03bc259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trustpilot = load_csv(RAW_PATH)\n",
    "df_trustpilot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29324067",
   "metadata": {},
   "source": [
    "### Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Missing Comments in Trustpilot Reviews Dataset:\", df_trustpilot[TEXT_COL].isna().sum())\n",
    "print(\"Number of duplicates in Trustpilot Reviews Dataset:\", df_trustpilot.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb5920a",
   "metadata": {},
   "source": [
    "### Apply Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "trustpilot_filter = TrustpilotDataFilter(\n",
    "    selected_columns=SELECTED_COLS,   # Columns to keep in final dataset\n",
    "    date_column=DATE_COL,           # Review date field\n",
    "    start_date=START_DATE,               # Inclusive start date\n",
    "    end_date=END_DATE,                   # Inclusive end date\n",
    "    country_code=COUNTRY_CODE,           # Filter to UK reviews only\n",
    "    text_column=TEXT_COL,                # Text used for language detection\n",
    "    allowed_languages=(DETECT_LANGUAGE ,)   # Keep English-language reviews\n",
    ")\n",
    "\n",
    "df_trustpilot = trustpilot_filter.apply(df_trustpilot)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate language filtering (approx. 1min - set to false to save time)\n",
    "VALIDATE_LANGUAGE = False\n",
    "if VALIDATE_LANGUAGE:\n",
    "    language_check = df_trustpilot[TEXT_COL].apply(detect_language)\n",
    "    language_counts = (\n",
    "        pd.Series(language_check)\n",
    "        .value_counts(dropna=False)\n",
    "        .sort_index()\n",
    "    )\n",
    "    display(language_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f5c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw filtered (no text preprocessing yet)\n",
    "save_csv(\n",
    "    df_trustpilot,\n",
    "    RAW_PATH,\n",
    "    suffix=\"_raw_filtered\",\n",
    ")\n",
    "\n",
    "print(\"Saved raw filtered dataset to:\", Path(RAW_PATH).with_name(f\"{Path(RAW_PATH).stem}_raw_filtered{Path(RAW_PATH).suffix}\"))\n",
    "display(df_trustpilot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee982d9",
   "metadata": {},
   "source": [
    "### Apply Text Preprocessor for Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text preprocessor for topic modelling\n",
    "df_trustpilot[TEXT_COL] = TextPreprocessor(\n",
    "    punctuation_pattern=PUNCTUATION_PATTERN_TOPIC,\n",
    "    extra_stopwords=EXTRA_STOPWORDS,\n",
    "    use_pos_tagging=USE_POS_TAGGING_TOPIC,\n",
    "    language=STOPWORD_LANGUAGE,\n",
    ").transform_many(df_trustpilot[TEXT_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4560b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_trustpilot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a223a281",
   "metadata": {},
   "source": [
    "### Save Processed Data for Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11739e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(\n",
    "    df_trustpilot,\n",
    "    RAW_PATH,\n",
    "    suffix=\"_preprocessed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdbe3b4",
   "metadata": {},
   "source": [
    "### Apply Text Preprocessor for Sentiment/Emotion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cac72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text preprocessor for sentiment/emotion data\n",
    "df_trustpilot_sentiment = df_trustpilot.copy()\n",
    "\n",
    "df_trustpilot_sentiment[TEXT_COL] = TextPreprocessor(\n",
    "    punctuation_pattern=PUNCTUATION_PATTERN_SENTIMENT,\n",
    "    extra_stopwords=EXTRA_STOPWORDS,\n",
    "    use_pos_tagging=USE_POS_TAGGING_SENTIMENT,\n",
    "    language=STOPWORD_LANGUAGE,\n",
    ").transform_many(df_trustpilot_sentiment[TEXT_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4575187",
   "metadata": {},
   "source": [
    "### Save Processed Sentiment/Emotion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e820e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_save_path = save_csv(\n",
    "    df_trustpilot_sentiment,\n",
    "    RAW_PATH,\n",
    "    suffix=\"_preprocessed_sentiment\",\n",
    ")\n",
    "\n",
    "print(\"Saved sentiment/emotion preprocessed dataset to:\", sentiment_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d031c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_s = time.perf_counter() - NOTEBOOK_T0\n",
    "elapsed_m = elapsed_s / 60\n",
    "\n",
    "print(f\"\\nTotal runtime: {elapsed_s:,.1f} seconds ({elapsed_m:,.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c279d1",
   "metadata": {},
   "source": [
    "# 02_eda_and_split_negative_review_data\n",
    "\n",
    "This section performs exploratory analysis on the preprocessed dataset and prepares modelling subsets:\n",
    "\n",
    "- Produces word-frequency tables and word clouds for all reviews, negative reviews, and non-negative reviews.\n",
    "\n",
    "- Splits the dataset into negative and non-negative subsets using rating thresholds from the configuration.\n",
    "\n",
    "**Outputs (data/):**\n",
    "\n",
    "- `PureGym Customer Reviews_preprocessed_negative.csv`\n",
    "\n",
    "- `PureGym Customer Reviews_preprocessed_non_negative.csv`\n",
    "\n",
    "**Additional outputs:** plots and tables under `output/plots/02_eda_and_split_negative_review_data/` and `output/tables/02_eda_and_split_negative_review_data/`.\n",
    "\n",
    "**Compute and reproducibility:** CPU-only local execution, fixed random seed **901**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbfb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "NOTEBOOK_T0 = time.perf_counter()\n",
    "print(\"Notebook timer started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d552041",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"PLOT_DIR\"] / \"02_eda_and_split_negative_review_data\"\n",
    "TABLE_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"TABLE_DIR\"] / \"02_eda_and_split_negative_review_data\"\n",
    "\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# DATA\n",
    "DATA_DIR = (PROJECT_ROOT / CONFIG[\"DATA\"][\"DATA_DIR\"]).resolve()\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RAW_FILENAME = CONFIG[\"DATA\"][\"RAW_FILENAME\"]\n",
    "PREPROCESSED_FILENAME = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME\"]\n",
    "PREPROCESSED_PATH = f\"{DATA_DIR}/{PREPROCESSED_FILENAME}\"\n",
    "\n",
    "\n",
    "TEXT_COL = CONFIG[\"FILTERING\"][\"TEXT_COL\"]  \n",
    "SEED = CONFIG[\"REPRODUCIBILITY\"].getint(\"SEED\")\n",
    "\n",
    "\n",
    "TOP_N = 10 # Number of words to show in bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678118c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard\n",
    "import ast\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from typing import Iterable, Sequence, Optional\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Project utilities\n",
    "from utils.data_management.data_io import load_csv, save_csv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc2938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed Trustpilot data\n",
    "df_trustpilot = load_csv(PREPROCESSED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc1f28",
   "metadata": {},
   "source": [
    "### Plotter Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eedeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "    \"\"\"\n",
    "    Create, display, and save common NLP plots.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_dir: str | Path = \"output/plots\") -> None:\n",
    "        self._output_dir = Path(output_dir)\n",
    "        self._output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    @property\n",
    "    def output_dir(self) -> Path:\n",
    "        return self._output_dir\n",
    "\n",
    "    def _save_figure(self, fig: plt.Figure, filename: str) -> Path:\n",
    "        save_path = self._output_dir / filename\n",
    "        fig.savefig(save_path, bbox_inches=\"tight\")\n",
    "        return save_path\n",
    "\n",
    "    def plot_word_frequencies(\n",
    "        self,\n",
    "        words: Sequence[str],\n",
    "        counts: Sequence[int],\n",
    "        *,\n",
    "        title: str,\n",
    "        filename: str,\n",
    "        rotation: int = 45,\n",
    "        figsize: float = 6.0,\n",
    "        show: bool = True,\n",
    "    ) -> Path:\n",
    "        \"\"\"\n",
    "        Plot, display, and save a word frequency bar chart.\n",
    "        \"\"\"\n",
    "        if len(words) != len(counts):\n",
    "            raise ValueError(\"words and counts must have the same length\")\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(figsize, figsize))\n",
    "        ax.bar(words, counts)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Words\")\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "        ax.tick_params(axis=\"x\", rotation=rotation)\n",
    "        fig.tight_layout()\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "        path = self._save_figure(fig, filename)\n",
    "        plt.close(fig)\n",
    "        return path\n",
    "\n",
    "    def plot_wordcloud(\n",
    "        self,\n",
    "        tokens: Iterable[str],\n",
    "        *,\n",
    "        title: str,\n",
    "        filename: str,\n",
    "        seed: Optional[int] = None,\n",
    "        width: int = 800,\n",
    "        height: int = 800,\n",
    "        background_color: str = \"white\",\n",
    "        max_words: int = 200,\n",
    "        figsize: float = 6.0,\n",
    "        show: bool = True,\n",
    "    ) -> Path:\n",
    "        \"\"\"\n",
    "        Plot, display, and save a word cloud.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seed\n",
    "            Random seed for word cloud layout. If ``None``, randomness is uncontrolled.\n",
    "        \"\"\"\n",
    "        text = \" \".join(str(t) for t in tokens if t is not None)\n",
    "\n",
    "        wc = WordCloud(\n",
    "            width=width,\n",
    "            height=height,\n",
    "            background_color=background_color,\n",
    "            max_words=max_words,\n",
    "            random_state=seed,\n",
    "        ).generate(text)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(figsize, figsize))\n",
    "        ax.imshow(wc, interpolation=\"bilinear\")\n",
    "        ax.set_title(title)\n",
    "        ax.axis(\"off\")\n",
    "        fig.tight_layout()\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "        path = self._save_figure(fig, filename)\n",
    "        plt.close(fig)\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aea7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate plotter\n",
    "plotter = Plotter(output_dir=PLOT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682955cb",
   "metadata": {},
   "source": [
    "### Plots: All Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc33d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise preprocessed text\n",
    "tokens_trustpilot = (\n",
    "    df_trustpilot[TEXT_COL]\n",
    "    .dropna()\n",
    "    .astype(str)\n",
    "    .str.split()\n",
    "    .explode()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word frequency calculation\n",
    "token_counts = Counter(tokens_trustpilot)\n",
    "common_words = token_counts.most_common(TOP_N)\n",
    "\n",
    "# Save top words table\n",
    "df_top_words_all = pd.DataFrame(common_words, columns=[\"word\", \"count\"])\n",
    "df_top_words_all.to_csv(TABLE_DIR / \"trustpilot_top10_words.csv\", index=False)\n",
    "\n",
    "words, counts = zip(*common_words) if common_words else ([], [])\n",
    "\n",
    "# Plot and save word frequencies\n",
    "freq_plot_path = plotter.plot_word_frequencies(\n",
    "    words=words,\n",
    "    counts=counts,\n",
    "    title=\"Top 10 Most Common Words in Trustpilot Reviews\",\n",
    "    filename=\"trustpilot_top10_words.png\",\n",
    ")\n",
    "\n",
    "print(f\"Saved frequency plot to: {freq_plot_path}\")\n",
    "\n",
    "# Plot and save wordcloud\n",
    "wordcloud_path = plotter.plot_wordcloud(\n",
    "    tokens=tokens_trustpilot,\n",
    "    title=\"Word Cloud for Trustpilot Reviews\",\n",
    "    filename=\"trustpilot_wordcloud.png\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(f\"Saved wordcloud to: {wordcloud_path}\")\n",
    "print(f\"Saved top words table to: {TABLE_DIR / 'trustpilot_top10_words.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28144f8d",
   "metadata": {},
   "source": [
    "### Create and Save Sub-dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View counts for each Rating level\n",
    "df_trustpilot[\"Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4853ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into negative / non-negative\n",
    "NEGATIVE_RATINGS = ast.literal_eval(CONFIG[\"FILTERING\"].get(\"NEGATIVE_RATINGS\", \"[]\"))\n",
    "\n",
    "df_negative = df_trustpilot[df_trustpilot[\"Rating\"].isin(NEGATIVE_RATINGS)].copy()\n",
    "df_non_negative = df_trustpilot[~df_trustpilot[\"Rating\"].isin(NEGATIVE_RATINGS)].copy()\n",
    "\n",
    "print(\"Negative ratings:\", NEGATIVE_RATINGS)\n",
    "print(\"All reviews:\", len(df_trustpilot))\n",
    "print(\"Negative reviews:\", len(df_negative))\n",
    "print(\"Non-negative reviews:\", len(df_non_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save split datasets to data folder\n",
    "negative_suffix = \"_negative\"\n",
    "non_negative_suffix = \"_non_negative\"\n",
    "\n",
    "negative_save_path = save_csv(\n",
    "    df_negative,\n",
    "    PREPROCESSED_PATH,\n",
    "    suffix=negative_suffix,\n",
    ")\n",
    "\n",
    "non_negative_save_path = save_csv(\n",
    "    df_non_negative,\n",
    "    PREPROCESSED_PATH,\n",
    "    suffix=non_negative_suffix,\n",
    ")\n",
    "\n",
    "print(f\"Saved negative reviews to: {negative_save_path}\")\n",
    "print(f\"Saved non-negative reviews to: {non_negative_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9136a0",
   "metadata": {},
   "source": [
    "### Plots: Negative Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fccee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_negative = (\n",
    "    df_negative[TEXT_COL]\n",
    "    .dropna()\n",
    "    .astype(str)\n",
    "    .str.split()\n",
    "    .explode()\n",
    ")\n",
    "\n",
    "token_counts_negative = Counter(tokens_negative)\n",
    "common_words_negative = token_counts_negative.most_common(TOP_N)\n",
    "\n",
    "# Save top words table\n",
    "df_top_words_negative = pd.DataFrame(common_words_negative, columns=[\"word\", \"count\"])\n",
    "df_top_words_negative.to_csv(TABLE_DIR / \"trustpilot_negative_top10_words.csv\", index=False)\n",
    "\n",
    "words_neg, counts_neg = zip(*common_words_negative) if common_words_negative else ([], [])\n",
    "\n",
    "freq_plot_path_negative = plotter.plot_word_frequencies(\n",
    "    words=words_neg,\n",
    "    counts=counts_neg,\n",
    "    title=\"Top 10 Most Common Words in Negative Trustpilot Reviews\",\n",
    "    filename=\"trustpilot_negative_top10_words.png\",\n",
    ")\n",
    "\n",
    "print(f\"Saved negative frequency plot to: {freq_plot_path_negative}\")\n",
    "\n",
    "wordcloud_path_negative = plotter.plot_wordcloud(\n",
    "    tokens=tokens_negative,\n",
    "    title=\"Word Cloud for Negative Trustpilot Reviews\",\n",
    "    filename=\"trustpilot_negative_wordcloud.png\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(f\"Saved negative wordcloud to: {wordcloud_path_negative}\")\n",
    "print(f\"Saved negative top words table to: {TABLE_DIR / 'trustpilot_negative_top10_words.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ce26f",
   "metadata": {},
   "source": [
    "### Plots: Non-negative Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d0e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_non_negative = (\n",
    "    df_non_negative[TEXT_COL]\n",
    "    .dropna()\n",
    "    .astype(str)\n",
    "    .str.split()\n",
    "    .explode()\n",
    ")\n",
    "\n",
    "token_counts_non_negative = Counter(tokens_non_negative)\n",
    "common_words_non_negative = token_counts_non_negative.most_common(TOP_N)\n",
    "\n",
    "# Save top words table\n",
    "df_top_words_non_negative = pd.DataFrame(common_words_non_negative, columns=[\"word\", \"count\"])\n",
    "df_top_words_non_negative.to_csv(TABLE_DIR / \"trustpilot_non_negative_top10_words.csv\", index=False)\n",
    "\n",
    "words_non_neg, counts_non_neg = zip(*common_words_non_negative) if common_words_non_negative else ([], [])\n",
    "\n",
    "freq_plot_path_non_negative = plotter.plot_word_frequencies(\n",
    "    words=words_non_neg,\n",
    "    counts=counts_non_neg,\n",
    "    title=\"Top 10 Most Common Words in Non-negative Trustpilot Reviews\",\n",
    "    filename=\"trustpilot_non_negative_top10_words.png\",\n",
    ")\n",
    "\n",
    "print(f\"Saved non-negative frequency plot to: {freq_plot_path_non_negative}\")\n",
    "\n",
    "wordcloud_path_non_negative = plotter.plot_wordcloud(\n",
    "    tokens=tokens_non_negative,\n",
    "    title=\"Word Cloud for Non-negative Trustpilot Reviews\",\n",
    "    filename=\"trustpilot_non_negative_wordcloud.png\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(f\"Saved non-negative wordcloud to: {wordcloud_path_non_negative}\")\n",
    "print(f\"Saved non-negative top words table to: {TABLE_DIR / 'trustpilot_non_negative_top10_words.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b011e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_s = time.perf_counter() - NOTEBOOK_T0\n",
    "elapsed_m = elapsed_s / 60\n",
    "\n",
    "print(f\"\\nTotal runtime: {elapsed_s:,.1f} seconds ({elapsed_m:,.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe61bb9",
   "metadata": {},
   "source": [
    "# 03_topic_modelling_bertopic\n",
    "\n",
    "This section applies BERTopic topic modelling to:\n",
    "\n",
    "- Negative reviews\n",
    "\n",
    "UMAP is used for dimensionality reduction and visualisation, and summary tables and plots are saved for reporting.\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "- Models: `output/models/03_topic_modelling_bertopic/`\n",
    "\n",
    "- Tables: `output/tables/03_topic_modelling_bertopic/`\n",
    "\n",
    "- Plots: `output/plots/03_topic_modelling_bertopic/`\n",
    "\n",
    "**Compute and reproducibility:** CPU-only local execution, fixed random seed **901**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e794b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deded383",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_T0 = time.perf_counter()\n",
    "print(\"Notebook timer started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7d1888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERTopic Runner\n",
    "from modelling.bertopic.bertopic_runner import BERTopicRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = (PROJECT_ROOT / CONFIG[\"DATA\"][\"DATA_DIR\"])\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PREPROCESSED_FILENAME = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME\"]\n",
    "PREPROCESSED_PATH = f\"{DATA_DIR}/{PREPROCESSED_FILENAME}\"\n",
    "\n",
    "TEXT_COL = CONFIG[\"FILTERING\"][\"TEXT_COL\"]\n",
    "NEGATIVE_RATINGS = ast.literal_eval(CONFIG[\"FILTERING\"].get(\"NEGATIVE_RATINGS\", \"[]\"))\n",
    "SEED = CONFIG[\"REPRODUCIBILITY\"].getint(\"SEED\")\n",
    "\n",
    "PLOT_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"PLOT_DIR\"] / \"03_topic_modelling_bertopic\"\n",
    "TABLE_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"TABLE_DIR\"] / \"03_topic_modelling_bertopic\"\n",
    "MODEL_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"MODEL_DIR\"] / \"03_topic_modelling_bertopic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_TOPICS = 4\n",
    "N_WORDS_BARCHART = 5\n",
    "SHOW_PLOTS = True\n",
    "SAVE_PNG = True\n",
    "PNG_SCALE = 2\n",
    "\n",
    "UMAP_N_NEIGHBOURS = 15\n",
    "UMAP_N_COMPONENTS = 5\n",
    "UMAP_MIN_DIST = 0\n",
    "UMAP_METRIC = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_csv(PREPROCESSED_PATH)\n",
    "df_negative = df[df[\"Rating\"].isin(NEGATIVE_RATINGS)].copy()\n",
    "df_non_negative = df[~df[\"Rating\"].isin(NEGATIVE_RATINGS)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef61f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = BERTopicRunner(\n",
    "    model_dir=MODEL_DIR,\n",
    "    plot_dir=PLOT_DIR,\n",
    "    table_dir=TABLE_DIR,\n",
    "    seed=SEED,\n",
    "    min_topic_size=40,\n",
    "\n",
    "    # Topic-level controls\n",
    "    top_n_topics=TOP_N_TOPICS,\n",
    "    n_words_barchart=N_WORDS_BARCHART,\n",
    "\n",
    "    # Plotting controls\n",
    "    show_plots=SHOW_PLOTS,\n",
    "    save_png=SAVE_PNG,\n",
    "    png_scale=PNG_SCALE,\n",
    "\n",
    "    # UMAP controls\n",
    "    umap_n_neighbors=UMAP_N_NEIGHBOURS,\n",
    "    umap_n_components=UMAP_N_COMPONENTS,\n",
    "    umap_min_dist=UMAP_MIN_DIST,\n",
    "    umap_metric=UMAP_METRIC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8cab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_result = runner.run(df_negative, label=\"negative\", text_col=TEXT_COL, verbose=True)\n",
    "print(neg_result.plot_paths)\n",
    "display(neg_result.topic_info.head(3))\n",
    "display(neg_result.top_topics_table.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a98b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_s = time.perf_counter() - NOTEBOOK_T0\n",
    "elapsed_m = elapsed_s / 60\n",
    "\n",
    "print(f\"\\nTotal runtime: {elapsed_s:,.1f} seconds ({elapsed_m:,.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdab125",
   "metadata": {},
   "source": [
    "# 04a_emotion_analysis_roberta\n",
    "\n",
    "This section performs transformer-based emotion classification using a DistilRoBERTa emotion model:\n",
    "\n",
    "- Runs token-length diagnostics to inform a conservative `max_length` choice.\n",
    "\n",
    "- Performs batched inference to assign a dominant emotion label and confidence score to each review.\n",
    "\n",
    "- Splits emotion-annotated data into negative and non-negative subsets.\n",
    "\n",
    "- Produces emotion distribution tables and bar plots for all, negative, and non-negative reviews.\n",
    "\n",
    "**Outputs (data/):**\n",
    "- `PureGym Customer Reviews_preprocessed_emotion.csv`\n",
    "\n",
    "- `PureGym Customer Reviews_preprocessed_negative_emotion.csv`\n",
    "\n",
    "- `PureGym Customer Reviews_preprocessed_non_negative_emotion.csv`\n",
    "\n",
    "**Additional outputs:** plots and tables under `output/plots/04a_emotion_analysis/` and `output/tables/04a_emotion_analysis/`.\n",
    "\n",
    "**Compute and reproducibility:** CPU-only local execution, fixed random seed **901**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5a0ea",
   "metadata": {},
   "source": [
    "### Emotion Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db449e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "class Initialiser:\n",
    "    \"\"\"Initialise tokenizer and model for emotion sequence classification.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def init_tokenizer(model_name: str) -> AutoTokenizer:\n",
    "        return AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_model(model_name: str) -> AutoModelForSequenceClassification:\n",
    "        return AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f63ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EmotionParams:\n",
    "    \"\"\"\n",
    "    Central config for the emotion classification model run.\n",
    "    \"\"\"\n",
    "\n",
    "    MODEL_NAME_V1: str = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "    MODEL_NAME_V2: str = \"bhadresh-savani/bert-base-uncased-emotion\"\n",
    "\n",
    "    DEVICE: str = \"cpu\"\n",
    "\n",
    "    BATCH_SIZE: int = 16\n",
    "    MAX_LENGTH: int = 192\n",
    "\n",
    "    PADDING: bool = True\n",
    "    TRUNCATION: bool = True\n",
    "\n",
    "    LABEL_COL: str = \"Dominant Emotion\"\n",
    "    SCORE_COL: str = \"Confidence Score\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa0ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Any\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "class EmotionModelDataCompiler:\n",
    "    \"\"\"\n",
    "    Apply a Hugging Face emotion sequence classification model to a DataFrame text column.\n",
    "\n",
    "    The compiler tokenises text in batches, runs the model in inference mode, and\n",
    "    appends two columns to the returned DataFrame:\n",
    "    - predicted label (string)\n",
    "    - confidence score (float, max softmax probability)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df\n",
    "        Input DataFrame containing the text to classify.\n",
    "    text_col\n",
    "        Name of the column in ``df`` containing the text.\n",
    "    tokenizer\n",
    "        Hugging Face tokenizer used to encode text.\n",
    "    model\n",
    "        Hugging Face sequence classification model.\n",
    "    device\n",
    "        Torch device string, for example \"cpu\" or \"cuda\".\n",
    "    batch_size\n",
    "        Number of texts per inference batch.\n",
    "    max_length\n",
    "        Maximum token length for truncation.\n",
    "    label_col\n",
    "        Output column name for predicted labels.\n",
    "    score_col\n",
    "        Output column name for confidence scores.\n",
    "    padding\n",
    "        Whether to pad sequences in a batch (passed to the tokenizer).\n",
    "    truncation\n",
    "        Whether to truncate sequences to ``max_length`` (passed to the tokenizer).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        df: pd.DataFrame,\n",
    "        text_col: str,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        model: AutoModelForSequenceClassification,\n",
    "        device: str,\n",
    "        batch_size: int,\n",
    "        max_length: int,\n",
    "        label_col: str,\n",
    "        score_col: str,\n",
    "        padding: bool,\n",
    "        truncation: bool,\n",
    "    ) -> None:\n",
    "\n",
    "        if text_col not in df.columns:\n",
    "            raise KeyError(f\"'{text_col}' not found in DataFrame\")\n",
    "\n",
    "        # Store core inputs for later use\n",
    "        self._df = df\n",
    "        self._text_col = text_col\n",
    "\n",
    "        self._tokenizer = tokenizer\n",
    "        self._model = model\n",
    "        self._device = torch.device(device)\n",
    "\n",
    "        # Store inference settings (batching + tokenisation behaviour)\n",
    "        self._batch_size = batch_size\n",
    "        self._max_length = max_length\n",
    "        self._padding = padding\n",
    "        self._truncation = truncation\n",
    "\n",
    "        # Store output column names\n",
    "        self._label_col = label_col\n",
    "        self._score_col = score_col\n",
    "\n",
    "        # Ensure model is on the correct device and set to inference mode\n",
    "        self._model.to(self._device)\n",
    "        self._model.eval()\n",
    "\n",
    "        # Map numeric class ids to human-readable labels (falls back to id if missing)\n",
    "        id2label = getattr(self._model.config, \"id2label\", None) or {}\n",
    "        self._id2label = {int(k): str(v) for k, v in id2label.items()}\n",
    "\n",
    "    def apply(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Run inference over the configured DataFrame and append label and score columns.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            Copy of the input DataFrame with two additional columns.\n",
    "        \"\"\"\n",
    "\n",
    "        df_out = self._df.copy()\n",
    "\n",
    "        # Clean text inputs (avoid NaNs, enforce string type, remove surrounding whitespace)\n",
    "        texts = (\n",
    "            df_out[self._text_col]\n",
    "            .fillna(\"\")\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .tolist()\n",
    "        )\n",
    "\n",
    "        # Run model inference to obtain labels and confidence scores\n",
    "        labels, scores = self._predict(texts)\n",
    "\n",
    "        # Append outputs back onto the DataFrame in the same row order\n",
    "        df_out[self._label_col] = labels\n",
    "        df_out[self._score_col] = scores\n",
    "        return df_out\n",
    "\n",
    "    def _predict(self, texts: list[str]) -> Tuple[list[str], list[float]]:\n",
    "        \"\"\"\n",
    "        Predict labels and confidence scores for a list of texts.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        texts\n",
    "            List of input texts.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[list[str], list[float]]\n",
    "            Predicted labels and confidence scores aligned to ``texts``.\n",
    "        \"\"\"\n",
    "        out_labels: list[str] = []\n",
    "        out_scores: list[float] = []\n",
    "\n",
    "        # Handle empty input explicitly (keeps behaviour predictable for callers)\n",
    "        if not texts:\n",
    "            return out_labels, out_scores\n",
    "\n",
    "        # Process texts in batches \n",
    "        for start in range(0, len(texts), self._batch_size):\n",
    "            batch = texts[start : start + self._batch_size]\n",
    "\n",
    "            # Tokenise the batch using the configured padding/truncation strategy\n",
    "            enc = self._tokenizer(\n",
    "                batch,\n",
    "                padding=self._padding,\n",
    "                truncation=self._truncation,\n",
    "                max_length=self._max_length,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "            # Move tokenised tensors onto the same device as the model\n",
    "            enc = {k: v.to(self._device) for k, v in enc.items()}\n",
    "\n",
    "            # Inference only: disable gradients to reduce memory and improve speed\n",
    "            with torch.no_grad():\n",
    "                logits = self._model(**enc).logits\n",
    "\n",
    "            # Convert logits to probabilities, then pick the highest-probability class\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            best_scores, best_ids = torch.max(probs, dim=-1)\n",
    "\n",
    "            # Convert tensors to plain Python types and map ids to label strings\n",
    "            for label_id, score in zip(\n",
    "                best_ids.detach().cpu().numpy(),\n",
    "                best_scores.detach().cpu().numpy(),\n",
    "            ):\n",
    "                label = self._id2label.get(int(label_id), str(int(label_id)))\n",
    "                out_labels.append(label)\n",
    "                out_scores.append(float(score))\n",
    "\n",
    "        return out_labels, out_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e4d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single helper function for bar charts\n",
    "def bar_plot(\n",
    "    counts: pd.Series,\n",
    "    *,\n",
    "    title: str,\n",
    "    x_label: str,\n",
    "    y_label: str,\n",
    "    figsize: tuple[float, float] = (7.0, 7.0),\n",
    "    rotation: int = 45,\n",
    "    show: bool = True,\n",
    "    save: bool = False,\n",
    "    output_dir: Optional[Path] = None,\n",
    "    filename: Optional[str] = None,\n",
    "    dpi: int = 150,\n",
    "    print_path: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot a categorical bar chart from a frequency Series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts\n",
    "        Counts indexed by category (x-axis labels).\n",
    "    title\n",
    "        Plot title.\n",
    "    x_label\n",
    "        X-axis label.\n",
    "    y_label\n",
    "        Y-axis label.\n",
    "    figsize\n",
    "        Figure size in inches.\n",
    "    rotation\n",
    "        Rotation for x tick labels.\n",
    "    show\n",
    "        If True, display the figure.\n",
    "    save\n",
    "        If True, save the figure to disk.\n",
    "    output_dir\n",
    "        Output directory used when ``save=True``.\n",
    "    filename\n",
    "        Output filename used when ``save=True``.\n",
    "    dpi\n",
    "        Resolution used when saving.\n",
    "    print_path\n",
    "        If True and ``save=True``, print the saved path.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If ``save=True`` and ``output_dir`` or ``filename`` is not provided.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    x = counts.index.astype(str)\n",
    "    y = counts.to_numpy()\n",
    "    ax.bar(x, y)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.tick_params(axis=\"x\", rotation=rotation)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        if output_dir is None or filename is None:\n",
    "            plt.close(fig)\n",
    "            raise ValueError(\"When save=True, both output_dir and filename must be provided.\")\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        out_path = output_dir / filename\n",
    "        fig.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "        if print_path:\n",
    "            print(\"Saved plot to:\", out_path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0290e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_T0 = time.perf_counter()\n",
    "print(\"Notebook timer started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95453c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_management.data_io import load_csv, save_csv\n",
    "\n",
    "DATA_DIR = (PROJECT_ROOT / CONFIG[\"DATA\"][\"DATA_DIR\"])\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PREPROCESSED_FILENAME = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME_SENTIMENT\"]\n",
    "PREPROCESSED_PATH = f\"{DATA_DIR}/{PREPROCESSED_FILENAME}\"\n",
    "\n",
    "TEXT_COL = CONFIG[\"FILTERING\"][\"TEXT_COL\"]\n",
    "NEGATIVE_RATINGS = ast.literal_eval(CONFIG[\"FILTERING\"].get(\"NEGATIVE_RATINGS\", \"[]\"))\n",
    "SEED = CONFIG[\"REPRODUCIBILITY\"].getint(\"SEED\")\n",
    "\n",
    "PLOT_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"PLOT_DIR\"] / \"04a_emotion_analysis\"\n",
    "TABLE_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"TABLE_DIR\"] / \"04a_emotion_analysis\"\n",
    "\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = CONFIG[\"REPRODUCIBILITY\"].getint(\"SEED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0975a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGSIZE = (7, 7)\n",
    "DPI = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "preprocessed_path = Path(DATA_DIR / PREPROCESSED_FILENAME)\n",
    "PREPROCESSED_PATH = str(preprocessed_path)\n",
    "print(\"PREPROCESSED_PATH:\", PREPROCESSED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc92a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_FILENAME_EMOTION = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME_EMOTION\"]\n",
    "PREPROCESSED_FILENAME_NEGATIVE_EMOTION = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME_NEGATIVE_EMOTION\"]\n",
    "PREPROCESSED_FILENAME_NON_NEGATIVE_EMOTION = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME_NON_NEGATIVE_EMOTION\"]\n",
    "\n",
    "ALL_EMOTION_PATH = Path(DATA_DIR) / PREPROCESSED_FILENAME_EMOTION\n",
    "NEG_EMOTION_PATH = Path(DATA_DIR) / PREPROCESSED_FILENAME_NEGATIVE_EMOTION\n",
    "NON_NEG_EMOTION_PATH = Path(DATA_DIR) / PREPROCESSED_FILENAME_NON_NEGATIVE_EMOTION\n",
    "\n",
    "print(\"ALL_EMOTION_PATH:\", ALL_EMOTION_PATH)\n",
    "print(\"NEG_EMOTION_PATH:\", NEG_EMOTION_PATH)\n",
    "print(\"NON_NEG_EMOTION_PATH:\", NON_NEG_EMOTION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed dataset only (single inference run)\n",
    "\n",
    "df_all = load_csv(PREPROCESSED_PATH)\n",
    "print(\"All reviews:\", len(df_all))\n",
    "display(df_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f98587",
   "metadata": {},
   "source": [
    "## Token Length EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a98333",
   "metadata": {},
   "source": [
    "* The max_length has been conservatively set to 192 in the EmotionParams file based on the above (see import path in cell above). This has been kept constant for emotion based models.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Token Length EDA\n",
    "RUN_TOKEN_LENGTH_DIAGNOSTICS = True  # set True to run diagnostics\n",
    "\n",
    "if RUN_TOKEN_LENGTH_DIAGNOSTICS:\n",
    "    MAXLEN_CANDIDATES = [64, 96, 128, 160, 192, 256, 320, 384, 448, 512]\n",
    "    df_for_profile = df_all \n",
    "\n",
    "    texts = (df_for_profile[TEXT_COL].fillna(\"\").astype(str).str.strip())\n",
    "    texts = texts.loc[texts.ne(\"\")]\n",
    "\n",
    "    model_name_v1 = EmotionParams.MODEL_NAME_V1\n",
    "    model_name_v2 = EmotionParams.MODEL_NAME_V2\n",
    "\n",
    "    print(f\"Tokenizer/model V1: {model_name_v1}\")\n",
    "    print(f\"Tokenizer/model V2: {model_name_v2}\")\n",
    "\n",
    "    # Initialise both tokenisers based on model names\n",
    "    tokenizer_v1 = Initialiser.init_tokenizer(model_name_v1)\n",
    "    tokenizer_v2 = Initialiser.init_tokenizer(model_name_v2)\n",
    "\n",
    "    # Compute token lengths without truncation for each tokeniser\n",
    "    token_lengths_v1 = texts.apply(lambda t: len(tokenizer_v1.encode(t, add_special_tokens=True))).to_numpy()\n",
    "    token_lengths_v2 = texts.apply(lambda t: len(tokenizer_v2.encode(t, add_special_tokens=True))).to_numpy()\n",
    "\n",
    "    # Worst-case length per text across both tokenisers (safe choice for later max_length)\n",
    "    token_lengths_worst = np.maximum(token_lengths_v1, token_lengths_v2)\n",
    "\n",
    "    # % fully captured for each candidate max length\n",
    "    captured_pct_v1 = [(token_lengths_v1 <= L).mean() * 100 for L in MAXLEN_CANDIDATES]\n",
    "    captured_pct_v2 = [(token_lengths_v2 <= L).mean() * 100 for L in MAXLEN_CANDIDATES]\n",
    "    captured_pct_worst = [(token_lengths_worst <= L).mean() * 100 for L in MAXLEN_CANDIDATES]\n",
    "\n",
    "    # Summary stats\n",
    "    percentiles = [50, 75, 90, 95, 97, 99]\n",
    "    pvals_v1 = np.percentile(token_lengths_v1, percentiles)\n",
    "    pvals_v2 = np.percentile(token_lengths_v2, percentiles)\n",
    "\n",
    "    p99_v1 = float(np.percentile(token_lengths_v1, 99))\n",
    "    p99_v2 = float(np.percentile(token_lengths_v2, 99))\n",
    "    p99_max = max(p99_v1, p99_v2)\n",
    "\n",
    "    print(\"Token length percentiles (V1):\")\n",
    "    for p, v in zip(percentiles, pvals_v1):\n",
    "        print(f\"{p:>2}%: {int(v)} tokens\")\n",
    "\n",
    "    print(\"\\nToken length percentiles (V2):\")\n",
    "    for p, v in zip(percentiles, pvals_v2):\n",
    "        print(f\"{p:>2}%: {int(v)} tokens\")\n",
    "\n",
    "    print(f\"\\n99th percentile (V1): {int(p99_v1)} tokens\")\n",
    "    print(f\"99th percentile (V2): {int(p99_v2)} tokens\")\n",
    "    print(f\"Using larger 99th percentile across V1/V2: {int(p99_max)} tokens\")\n",
    "\n",
    "    print(\"\\nCapture by candidate max_length (%):\")\n",
    "    for L, p1, p2, pw in zip(MAXLEN_CANDIDATES, captured_pct_v1, captured_pct_v2, captured_pct_worst):\n",
    "        print(f\"{L:>3}: V1={p1:6.2f}% | V2={p2:6.2f}% | worst-case={pw:6.2f}%\")\n",
    "\n",
    "    best_L = next((L for L, p in zip(MAXLEN_CANDIDATES, captured_pct_worst) if p >= 99), None)\n",
    "    if best_L is not None:\n",
    "        print(f\"\\nFirst candidate max_length capturing ≥99% for BOTH tokenisers (worst-case): {best_L}.\")\n",
    "    else:\n",
    "        print(\"\\nNo candidate max_length reached 99% capture for BOTH tokenisers (consider adding larger values).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e895c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Initialiser.init_tokenizer(EmotionParams.MODEL_NAME_V1)\n",
    "model = Initialiser.init_model(EmotionParams.MODEL_NAME_V1)\n",
    "\n",
    "compiler = EmotionModelDataCompiler(\n",
    "    df=df_all,\n",
    "    text_col=TEXT_COL,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    device=EmotionParams.DEVICE,\n",
    "    batch_size=EmotionParams.BATCH_SIZE,\n",
    "    max_length=EmotionParams.MAX_LENGTH,\n",
    "    label_col=EmotionParams.LABEL_COL,\n",
    "    score_col=EmotionParams.SCORE_COL,\n",
    "    padding=EmotionParams.PADDING,\n",
    "    truncation=EmotionParams.TRUNCATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92353fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TAG = re.sub(r\"[^A-Za-z0-9]+\", \"_\", EmotionParams.MODEL_NAME_V1).strip(\"_\")\n",
    "\n",
    "# Print params \n",
    "print(\"\\nEmotionParams used:\")\n",
    "print(\"MODEL_NAME:\", EmotionParams.MODEL_NAME_V1)\n",
    "print(\"DEVICE:\", EmotionParams.DEVICE)\n",
    "print(\"BATCH_SIZE:\", EmotionParams.BATCH_SIZE)\n",
    "print(\"MAX_LENGTH:\", EmotionParams.MAX_LENGTH)\n",
    "print(\"PADDING:\", EmotionParams.PADDING)\n",
    "print(\"TRUNCATION:\", EmotionParams.TRUNCATION)\n",
    "print(\"LABEL_COL:\", EmotionParams.LABEL_COL)\n",
    "print(\"SCORE_COL:\", EmotionParams.SCORE_COL)\n",
    "print(\"TEXT_COL:\", TEXT_COL)\n",
    "print(\"Rows:\", len(df_all))\n",
    "\n",
    "print(\"Tokenizer class:\", type(tokenizer).__name__)\n",
    "print(\"Is fast tokenizer:\", getattr(tokenizer, \"is_fast\", False))\n",
    "print(\"Vocab size:\", tokenizer.vocab_size)\n",
    "print(\"Model max length:\", tokenizer.model_max_length)\n",
    "print(\"Pad token:\", tokenizer.pad_token, tokenizer.pad_token_id)\n",
    "print(\"EOS token:\", tokenizer.eos_token, tokenizer.eos_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf0def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply: All reviews (single inference run)\n",
    "df_all_emotion = compiler.apply()\n",
    "\n",
    "display(df_all_emotion[[TEXT_COL, EmotionParams.LABEL_COL, EmotionParams.SCORE_COL]].head(4))\n",
    "\n",
    "all_save_path = save_csv(df_all_emotion, f\"{DATA_DIR}/{PREPROCESSED_FILENAME_EMOTION}\", suffix=None)\n",
    "print(f\"Saved emotion-annotated all reviews to: {all_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd46eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split from annotated dataset \n",
    "df_negative_emotion = df_all_emotion[df_all_emotion[\"Rating\"].isin(NEGATIVE_RATINGS)].copy()\n",
    "df_non_negative_emotion = df_all_emotion[~df_all_emotion[\"Rating\"].isin(NEGATIVE_RATINGS)].copy()\n",
    "\n",
    "print(\"Negative reviews:\", len(df_negative_emotion))\n",
    "print(\"Non-negative reviews:\", len(df_non_negative_emotion))\n",
    "\n",
    "display(df_negative_emotion[[TEXT_COL, EmotionParams.LABEL_COL, EmotionParams.SCORE_COL]].head(4))\n",
    "display(df_non_negative_emotion[[TEXT_COL, EmotionParams.LABEL_COL, EmotionParams.SCORE_COL]].head(4))\n",
    "\n",
    "neg_save_path = save_csv(df_negative_emotion, f\"{DATA_DIR}/{PREPROCESSED_FILENAME_NEGATIVE_EMOTION}\", suffix=None)\n",
    "print(f\"Saved emotion-annotated negative reviews to: {neg_save_path}\")\n",
    "\n",
    "non_neg_save_path = save_csv(df_non_negative_emotion, PREPROCESSED_PATH, suffix=\"_non_negative_emotion\")\n",
    "non_neg_save_path = save_csv(df_non_negative_emotion, f\"{DATA_DIR}/{PREPROCESSED_FILENAME_NON_NEGATIVE_EMOTION}\", suffix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48963547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables and Plots: All reviews\n",
    "counts_all = df_all_emotion[EmotionParams.LABEL_COL].value_counts(dropna=False)\n",
    "counts_all_df = counts_all.rename_axis(\"Emotion\").reset_index(name=\"Count\")\n",
    "display(counts_all_df)\n",
    "\n",
    "out_path = TABLE_DIR / f\"emotion_counts_all_reviews_{MODEL_TAG}.csv\"\n",
    "counts_all_df.to_csv(out_path, index=False)\n",
    "print(\"Saved table to:\", out_path)\n",
    "\n",
    "bar_plot(\n",
    "    counts_all,\n",
    "    title=\"Emotion Distribution (All Reviews)\",\n",
    "    x_label=\"Emotion\",\n",
    "    y_label=\"Frequency\",\n",
    "    figsize=FIGSIZE,\n",
    "    show=True,\n",
    "    save=True,\n",
    "    output_dir=PLOT_DIR,\n",
    "    filename=f\"emotion_distribution_all_reviews_{MODEL_TAG}.png\",\n",
    "    dpi=DPI,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ef22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables and Plots: Negative reviews\n",
    "counts_neg = df_negative_emotion[EmotionParams.LABEL_COL].value_counts(dropna=False)\n",
    "counts_neg_df = counts_neg.rename_axis(\"Emotion\").reset_index(name=\"Count\")\n",
    "display(counts_neg_df)\n",
    "\n",
    "out_path = TABLE_DIR / f\"emotion_counts_negative_reviews_{MODEL_TAG}.csv\"\n",
    "counts_neg_df.to_csv(out_path, index=False)\n",
    "print(\"Saved table to:\", out_path)\n",
    "\n",
    "bar_plot(\n",
    "    counts_neg,\n",
    "    title=\"Emotion Distribution (Negative Reviews)\",\n",
    "    x_label=\"Emotion\",\n",
    "    y_label=\"Frequency\",\n",
    "    figsize=FIGSIZE,\n",
    "    show=True,\n",
    "    save=True,\n",
    "    output_dir=PLOT_DIR,\n",
    "    filename=f\"emotion_distribution_negative_reviews_{MODEL_TAG}.png\",\n",
    "    dpi=DPI,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed0b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables and Plots: Non-negative reviews\n",
    "counts_non_neg = df_non_negative_emotion[EmotionParams.LABEL_COL].value_counts(dropna=False)\n",
    "counts_non_neg_df = counts_non_neg.rename_axis(\"Emotion\").reset_index(name=\"Count\")\n",
    "display(counts_non_neg_df)\n",
    "\n",
    "out_path = TABLE_DIR / f\"emotion_counts_non_negative_reviews_{MODEL_TAG}.csv\"\n",
    "counts_non_neg_df.to_csv(out_path, index=False)\n",
    "print(\"Saved table to:\", out_path)\n",
    "\n",
    "bar_plot(\n",
    "    counts_non_neg,\n",
    "    title=\"Emotion Distribution (Non-negative Reviews)\",\n",
    "    x_label=\"Emotion\",\n",
    "    y_label=\"Frequency\",\n",
    "    figsize=FIGSIZE,\n",
    "    show=True,\n",
    "    save=True,\n",
    "    output_dir=PLOT_DIR,\n",
    "    filename=f\"emotion_distribution_non_negative_reviews_{MODEL_TAG}.png\",\n",
    "    dpi=DPI,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dfaeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_s = time.perf_counter() - NOTEBOOK_T0\n",
    "elapsed_m = elapsed_s / 60\n",
    "\n",
    "print(f\"\\nTotal runtime: {elapsed_s:,.1f} seconds ({elapsed_m:,.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022ec729",
   "metadata": {},
   "source": [
    "# 04b_emotion_analysis_bert_base_uncased\n",
    "\n",
    "This section repeats emotion classification with a second model (BERT base uncased emotion) to support model comparison:\n",
    "\n",
    "- Runs batched inference to assign a dominant emotion label and confidence score.\n",
    "\n",
    "- Splits results into negative and non-negative subsets.\n",
    "\n",
    "- Produces summary tables and bar plots for all, negative, and non-negative reviews.\n",
    "\n",
    "**Outputs:** plots and summary tables under `output/plots/04b_emotion_analysis/` and `output/tables/04b_emotion_analysis/`.\n",
    "\n",
    "**Compute and reproducibility:** CPU-only local execution, fixed random seed **901**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa91da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "NOTEBOOK_T0 = time.perf_counter()\n",
    "print(\"Notebook timer started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe3121",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"PLOT_DIR\"] / \"04b_emotion_analysis\"\n",
    "TABLE_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"TABLE_DIR\"] / \"04b_emotion_analysis\"\n",
    "\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLE_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4bcef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGSIZE = (7, 7)\n",
    "DPI = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "preprocessed_path = Path(DATA_DIR / PREPROCESSED_FILENAME)\n",
    "PREPROCESSED_PATH = str(preprocessed_path)\n",
    "print(\"PREPROCESSED_PATH:\", PREPROCESSED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37143127",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_FILENAME_EMOTION = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME_EMOTION\"]\n",
    "PREPROCESSED_FILENAME_NEGATIVE_EMOTION = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME_NEGATIVE_EMOTION\"]\n",
    "PREPROCESSED_FILENAME_NON_NEGATIVE_EMOTION = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME_NON_NEGATIVE_EMOTION\"]\n",
    "\n",
    "ALL_EMOTION_PATH = Path(DATA_DIR) / PREPROCESSED_FILENAME_EMOTION\n",
    "NEG_EMOTION_PATH = Path(DATA_DIR) / PREPROCESSED_FILENAME_NEGATIVE_EMOTION\n",
    "NON_NEG_EMOTION_PATH = Path(DATA_DIR) / PREPROCESSED_FILENAME_NON_NEGATIVE_EMOTION\n",
    "\n",
    "print(\"ALL_EMOTION_PATH:\", ALL_EMOTION_PATH)\n",
    "print(\"NEG_EMOTION_PATH:\", NEG_EMOTION_PATH)\n",
    "print(\"NON_NEG_EMOTION_PATH:\", NON_NEG_EMOTION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5b1645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed dataset only (single inference run)\n",
    "\n",
    "df_all = load_csv(PREPROCESSED_PATH)\n",
    "print(\"All reviews:\", len(df_all))\n",
    "display(df_all.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d88d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Initialiser.init_tokenizer(EmotionParams.MODEL_NAME_V2)\n",
    "model = Initialiser.init_model(EmotionParams.MODEL_NAME_V2)\n",
    "\n",
    "compiler = EmotionModelDataCompiler(\n",
    "    df=df_all,\n",
    "    text_col=TEXT_COL,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    device=EmotionParams.DEVICE,\n",
    "    batch_size=EmotionParams.BATCH_SIZE,\n",
    "    max_length=EmotionParams.MAX_LENGTH,\n",
    "    label_col=EmotionParams.LABEL_COL,\n",
    "    score_col=EmotionParams.SCORE_COL,\n",
    "    padding=EmotionParams.PADDING,\n",
    "    truncation=EmotionParams.TRUNCATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TAG = re.sub(r\"[^A-Za-z0-9]+\", \"_\", EmotionParams.MODEL_NAME_V2).strip(\"_\")\n",
    "\n",
    "# Print params \n",
    "print(\"\\nEmotionParams used:\")\n",
    "print(\"MODEL_NAME:\", EmotionParams.MODEL_NAME_V2)\n",
    "print(\"DEVICE:\", EmotionParams.DEVICE)\n",
    "print(\"BATCH_SIZE:\", EmotionParams.BATCH_SIZE)\n",
    "print(\"MAX_LENGTH:\", EmotionParams.MAX_LENGTH)\n",
    "print(\"PADDING:\", EmotionParams.PADDING)\n",
    "print(\"TRUNCATION:\", EmotionParams.TRUNCATION)\n",
    "print(\"LABEL_COL:\", EmotionParams.LABEL_COL)\n",
    "print(\"SCORE_COL:\", EmotionParams.SCORE_COL)\n",
    "print(\"TEXT_COL:\", TEXT_COL)\n",
    "print(\"Rows:\", len(df_all))\n",
    "\n",
    "print(\"Tokenizer class:\", type(tokenizer).__name__)\n",
    "print(\"Is fast tokenizer:\", getattr(tokenizer, \"is_fast\", False))\n",
    "print(\"Vocab size:\", tokenizer.vocab_size)\n",
    "print(\"Model max length:\", tokenizer.model_max_length)\n",
    "print(\"Pad token:\", tokenizer.pad_token, tokenizer.pad_token_id)\n",
    "print(\"EOS token:\", tokenizer.eos_token, tokenizer.eos_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a50a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply: All reviews \n",
    "df_all_emotion = compiler.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9850ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split from annotated dataset \n",
    "df_negative_emotion = df_all_emotion[df_all_emotion[\"Rating\"].isin(NEGATIVE_RATINGS)].copy()\n",
    "df_non_negative_emotion = df_all_emotion[~df_all_emotion[\"Rating\"].isin(NEGATIVE_RATINGS)].copy()\n",
    "\n",
    "print(\"Negative reviews:\", len(df_negative_emotion))\n",
    "print(\"Non-negative reviews:\", len(df_non_negative_emotion))\n",
    "\n",
    "display(df_negative_emotion[[TEXT_COL, EmotionParams.LABEL_COL, EmotionParams.SCORE_COL]].head(4))\n",
    "display(df_non_negative_emotion[[TEXT_COL, EmotionParams.LABEL_COL, EmotionParams.SCORE_COL]].head(4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables and Plots: All reviews\n",
    "counts_all = df_all_emotion[EmotionParams.LABEL_COL].value_counts(dropna=False)\n",
    "counts_all_df = counts_all.rename_axis(\"Emotion\").reset_index(name=\"Count\")\n",
    "display(counts_all_df)\n",
    "\n",
    "out_path = TABLE_DIR / f\"emotion_counts_all_reviews_{MODEL_TAG}.csv\"\n",
    "counts_all_df.to_csv(out_path, index=False)\n",
    "print(\"Saved table to:\", out_path)\n",
    "\n",
    "bar_plot(\n",
    "    counts_all,\n",
    "    title=\"Emotion Distribution (All Reviews)\",\n",
    "    x_label=\"Emotion\",\n",
    "    y_label=\"Frequency\",\n",
    "    figsize=FIGSIZE,\n",
    "    show=True,\n",
    "    save=True,\n",
    "    output_dir=PLOT_DIR,\n",
    "    filename=f\"emotion_distribution_all_reviews_{MODEL_TAG}.png\",\n",
    "    dpi=DPI,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eed9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables and Plots: Negative reviews\n",
    "counts_neg = df_negative_emotion[EmotionParams.LABEL_COL].value_counts(dropna=False)\n",
    "counts_neg_df = counts_neg.rename_axis(\"Emotion\").reset_index(name=\"Count\")\n",
    "display(counts_neg_df)\n",
    "\n",
    "out_path = TABLE_DIR / f\"emotion_counts_negative_reviews_{MODEL_TAG}.csv\"\n",
    "counts_neg_df.to_csv(out_path, index=False)\n",
    "print(\"Saved table to:\", out_path)\n",
    "\n",
    "bar_plot(\n",
    "    counts_neg,\n",
    "    title=\"Emotion Distribution (Negative Reviews)\",\n",
    "    x_label=\"Emotion\",\n",
    "    y_label=\"Frequency\",\n",
    "    figsize=FIGSIZE,\n",
    "    show=True,\n",
    "    save=True,\n",
    "    output_dir=PLOT_DIR,\n",
    "    filename=f\"emotion_distribution_negative_reviews_{MODEL_TAG}.png\",\n",
    "    dpi=DPI,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02452aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables and Plots: Non-negative reviews\n",
    "counts_non_neg = df_non_negative_emotion[EmotionParams.LABEL_COL].value_counts(dropna=False)\n",
    "counts_non_neg_df = counts_non_neg.rename_axis(\"Emotion\").reset_index(name=\"Count\")\n",
    "display(counts_non_neg_df)\n",
    "\n",
    "out_path = TABLE_DIR / f\"emotion_counts_non_negative_reviews_{MODEL_TAG}.csv\"\n",
    "counts_non_neg_df.to_csv(out_path, index=False)\n",
    "print(\"Saved table to:\", out_path)\n",
    "\n",
    "bar_plot(\n",
    "    counts_non_neg,\n",
    "    title=\"Emotion Distribution (Non-negative Reviews)\",\n",
    "    x_label=\"Emotion\",\n",
    "    y_label=\"Frequency\",\n",
    "    figsize=FIGSIZE,\n",
    "    show=True,\n",
    "    save=True,\n",
    "    output_dir=PLOT_DIR,\n",
    "    filename=f\"emotion_distribution_non_negative_reviews_{MODEL_TAG}.png\",\n",
    "    dpi=DPI,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee71276",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_s = time.perf_counter() - NOTEBOOK_T0\n",
    "elapsed_m = elapsed_s / 60\n",
    "\n",
    "print(f\"\\nTotal runtime: {elapsed_s:,.1f} seconds ({elapsed_m:,.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099457c5",
   "metadata": {},
   "source": [
    "# 05_topic_modelling_bertopic_per_emotion_neg_reviews\n",
    "\n",
    "This section applies BERTopic to emotion-specific subsets of negative reviews (e.g. sadness) to obtain emotion-conditioned topics:\n",
    "\n",
    "- Loads emotion-annotated datasets.\n",
    "\n",
    "- Filters to negative reviews and subsets by dominant emotion, enforcing a minimum document threshold.\n",
    "\n",
    "- Fits BERTopic and saves topic summaries and plots.\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "- Models: `output/models/05_topic_modelling_bertopic_per_emotion_neg_reviews/`\n",
    "\n",
    "- Tables: `output/tables/05_topic_modelling_bertopic_per_emotion_neg_reviews/`\n",
    "\n",
    "- Plots: `output/plots/05_topic_modelling_bertopic_per_emotion_neg_reviews/`\n",
    "\n",
    "**Compute and reproducibility:** CPU-only local execution, fixed random seed **901**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3d8306",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_T0 = time.perf_counter()\n",
    "print(\"Section timer started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d7e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERTopic Runner\n",
    "from modelling.bertopic.bertopic_runner import BERTopicRunner\n",
    "\n",
    "PLOT_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"PLOT_DIR\"] / \"05_topic_modelling_bertopic_per_emotion_neg_reviews\"\n",
    "TABLE_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"TABLE_DIR\"] / \"05_topic_modelling_bertopic_per_emotion_neg_reviews\"\n",
    "MODEL_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"MODEL_DIR\"] / \"05_topic_modelling_bertopic_per_emotion_neg_reviews\"\n",
    "\n",
    "BERTOPIC_NEGATIVE_MODEL = CONFIG[\"MODELS\"][\"BERTOPIC_NEGATIVE\"]\n",
    "BERTOPIC_NON_NEGATIVE_MODEL = CONFIG[\"MODELS\"][\"BERTOPIC_NON_NEGATIVE\"]\n",
    "\n",
    "EMOTION_COL = CONFIG[\"FILTERING\"][\"EMOTION_COL\"]\n",
    "\n",
    "TOP_N_TOPICS = 4\n",
    "N_WORDS_BARCHART = 5\n",
    "SHOW_PLOTS = True\n",
    "SAVE_PNG = True\n",
    "PNG_SCALE = 2\n",
    "\n",
    "UMAP_N_NEIGHBOURS = 25\n",
    "UMAP_N_COMPONENTS = 5\n",
    "UMAP_MIN_DIST = 0\n",
    "UMAP_METRIC = \"cosine\"\n",
    "\n",
    "MIN_DOCS_PER_EMOTION = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3229f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_FILENAME_EMOTION = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME_EMOTION\"]\n",
    "PREPROCESSED_FILENAME_NEGATIVE_EMOTION = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME_NEGATIVE_EMOTION\"]\n",
    "PREPROCESSED_FILENAME_NON_NEGATIVE_EMOTION = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME_NON_NEGATIVE_EMOTION\"]\n",
    "\n",
    "ALL_EMOTION_PATH = Path(DATA_DIR) / PREPROCESSED_FILENAME_EMOTION\n",
    "NEG_EMOTION_PATH = Path(DATA_DIR) / PREPROCESSED_FILENAME_NEGATIVE_EMOTION\n",
    "NON_NEG_EMOTION_PATH = Path(DATA_DIR) / PREPROCESSED_FILENAME_NON_NEGATIVE_EMOTION\n",
    "\n",
    "print(\"ALL_EMOTION_PATH:\", ALL_EMOTION_PATH)\n",
    "print(\"NEG_EMOTION_PATH:\", NEG_EMOTION_PATH)\n",
    "print(\"NON_NEG_EMOTION_PATH:\", NON_NEG_EMOTION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc88df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load datasets with emotion column\n",
    "df_all_emotion = load_csv(ALL_EMOTION_PATH)\n",
    "df_negative_emotion = load_csv(NEG_EMOTION_PATH)\n",
    "df_non_negative_emotion = load_csv(NON_NEG_EMOTION_PATH)\n",
    "\n",
    "print(\"All emotion-annotated rows:\", len(df_all_emotion))\n",
    "print(\"Negative emotion-annotated rows:\", len(df_negative_emotion))\n",
    "print(\"Non-negative emotion-annotated rows:\", len(df_non_negative_emotion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723920d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise BERTopic runner\n",
    "runner = BERTopicRunner(\n",
    "    model_dir=MODEL_DIR,\n",
    "    plot_dir=PLOT_DIR,\n",
    "    table_dir=TABLE_DIR,\n",
    "    seed=SEED,\n",
    "\n",
    "    # Topic-level controls\n",
    "    top_n_topics=TOP_N_TOPICS,\n",
    "    n_words_barchart=N_WORDS_BARCHART,\n",
    "    min_topic_size = 25,\n",
    "\n",
    "    # Plotting controls\n",
    "    show_plots=SHOW_PLOTS,\n",
    "    save_png=SAVE_PNG,\n",
    "    png_scale=PNG_SCALE,\n",
    "\n",
    "    # UMAP controls\n",
    "    umap_n_neighbors=UMAP_N_NEIGHBOURS,\n",
    "    umap_n_components=UMAP_N_COMPONENTS,\n",
    "    umap_min_dist=UMAP_MIN_DIST,\n",
    "    umap_metric=UMAP_METRIC,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd6d70",
   "metadata": {},
   "source": [
    "#### Sadness (negative reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec10646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sadness (negative reviews)\n",
    "emotion = \"sadness\"\n",
    "subset = df_negative_emotion[df_negative_emotion[EMOTION_COL] == emotion].copy()\n",
    "\n",
    "print(f\"\\nNegative reviews with dominant emotion = '{emotion}': {len(subset)}\")\n",
    "\n",
    "if len(subset) < MIN_DOCS_PER_EMOTION:\n",
    "    print(f\"Skipping '{emotion}' (only {len(subset)} docs, need at least {MIN_DOCS_PER_EMOTION}).\")\n",
    "else:\n",
    "    label = f\"emotion_negative_{emotion}\"\n",
    "    result_sadness = runner.run(subset, label=label, text_col=TEXT_COL, verbose=True)\n",
    "\n",
    "    print(result_sadness.plot_paths)\n",
    "\n",
    "    topic_info_head = result_sadness.topic_info\n",
    "    top_topics_table = result_sadness.top_topics_table\n",
    "\n",
    "    topic_info_head.to_csv(TABLE_DIR / f\"{label}_topic_info_head10.csv\", index=False)\n",
    "    top_topics_table.to_csv(TABLE_DIR / f\"{label}_top_topics_table.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95434778",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_s = time.perf_counter() - NOTEBOOK_T0\n",
    "elapsed_m = elapsed_s / 60\n",
    "\n",
    "print(f\"\\nTotal runtime: {elapsed_s:,.1f} seconds ({elapsed_m:,.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e753682b",
   "metadata": {},
   "source": [
    "# 06_topic_modelling_lda_gensim\n",
    "\n",
    "This section runs classical topic modelling with Gensim LDA as a baseline against BERTopic:\n",
    "\n",
    "- Builds dictionary and bag-of-words corpora from preprocessed tokens.\n",
    "\n",
    "- Trains (or loads) LDA models for multiple subsets (all reviews, negative reviews, and selected emotion subsets).\n",
    "\n",
    "- Evaluates with c_v coherence and exports topic tables aligned to pyLDAvis numbering.\n",
    "\n",
    "- Produces interactive pyLDAvis HTML visualisations.\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "- Models and artefacts: `output/models/06_topic_modelling_lda_gensim/` (including `gensim_lda_runs/`)\n",
    "\n",
    "- Tables: `output/tables/06_topic_modelling_lda_gensim/`\n",
    "\n",
    "- Visualisations: `output/plots/06_topic_modelling_lda_gensim/`\n",
    "\n",
    "**Compute and reproducibility:** CPU-only local execution, fixed random seed **901**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da78ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timer start\n",
    "import time\n",
    "\n",
    "NOTEBOOK_T0 = time.perf_counter()\n",
    "print(\"Notebook timer started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gensim imports \n",
    "from gensim import corpora\n",
    "from gensim.corpora import MmCorpus\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "\n",
    "PREPROCESSED_FILENAME = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME\"]\n",
    "PREPROCESSED_FILENAME_NEGATIVE = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME_NEGATIVE\"]\n",
    "PREPROCESSED_FILENAME_NEGATIVE_EMOTION = CONFIG[\"DATA\"][\"PREPROCESSED_FILENAME_NEGATIVE_EMOTION\"]\n",
    "\n",
    "PREPROCESSED_PATH = f\"{DATA_DIR}/{PREPROCESSED_FILENAME}\"\n",
    "PREPROCESSED_NEG_PATH = f\"{DATA_DIR}/{PREPROCESSED_FILENAME_NEGATIVE}\"\n",
    "PREPROCESSED_NEG_EMO_PATH = f\"{DATA_DIR}/{PREPROCESSED_FILENAME_NEGATIVE_EMOTION}\"\n",
    "\n",
    "EMOTION_COL = CONFIG[\"FILTERING\"][\"EMOTION_COL\"]\n",
    "\n",
    "# OUTPUT\n",
    "PLOT_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"PLOT_DIR\"] / \"06_topic_modelling_lda_gensim\"\n",
    "TABLE_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"TABLE_DIR\"] / \"06_topic_modelling_lda_gensim\"\n",
    "MODEL_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"MODEL_DIR\"] / \"06_topic_modelling_lda_gensim\"\n",
    "\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "print(\"PREPROCESSED_PATH:\", PREPROCESSED_PATH)\n",
    "print(\"PREPROCESSED_NEG_PATH:\", PREPROCESSED_NEG_PATH)\n",
    "print(\"PREPROCESSED_NEG_EMO_PATH:\", PREPROCESSED_NEG_EMO_PATH)\n",
    "print(\"TEXT_COL:\", TEXT_COL)\n",
    "print(\"EMOTION_COL:\", EMOTION_COL)\n",
    "print(\"SEED:\", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e34095",
   "metadata": {},
   "source": [
    "## LDA Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class LDAConfig:\n",
    "    \"\"\"\n",
    "    Configuration for a Gensim LDA run.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ...\n",
    "    alpha\n",
    "        Document-topic Dirichlet prior. Can be a float, \"symmetric\", \"asymmetric\", or \"auto\".\n",
    "    eta\n",
    "        Topic-word Dirichlet prior. Can be a float, \"symmetric\", or \"auto\".\n",
    "    \"\"\"\n",
    "\n",
    "    seed: int\n",
    "    train_new_model: bool\n",
    "    num_topics: int\n",
    "    passes: int\n",
    "    chunksize: int\n",
    "    iterations: int\n",
    "    eval_every: Any\n",
    "    no_below: int\n",
    "    no_above: float\n",
    "    top_n_words: int\n",
    "    plot_dir: Path\n",
    "    table_dir: Path\n",
    "    model_dir: Path\n",
    "    alpha: Optional[Any] = None\n",
    "    eta: Optional[Any] = None\n",
    "\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class LDARunResult:\n",
    "    \"\"\"\n",
    "    Outputs from a single LDA run.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label\n",
    "        Run label used for filenames.\n",
    "    model_path\n",
    "        Path to the saved/loaded LDA model.\n",
    "    dict_path\n",
    "        Path to the saved dictionary.\n",
    "    corpus_path\n",
    "        Path to the saved corpus (.mm).\n",
    "    topics_csv\n",
    "        Path to the saved topics summary CSV.\n",
    "    vis_path\n",
    "        Path to the saved pyLDAvis HTML file.\n",
    "    coherence_cv\n",
    "        c_v coherence score.\n",
    "    topics_table\n",
    "        DataFrame of topic ids and top words.\n",
    "    vis\n",
    "        pyLDAvis prepared visualisation object.\n",
    "    \"\"\"\n",
    "\n",
    "    label: str\n",
    "    model_path: Path\n",
    "    dict_path: Path\n",
    "    corpus_path: Path\n",
    "    topics_csv: Path\n",
    "    vis_path: Path\n",
    "    coherence_cv: float\n",
    "    topics_table: pd.DataFrame\n",
    "    vis: Any\n",
    "\n",
    "\n",
    "class LDAArtefactStore:\n",
    "    \"\"\"Handle file paths and persistence for dictionary, corpus, and model.\"\"\"\n",
    "\n",
    "    def __init__(self, model_dir: Path) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_dir\n",
    "            Root directory for saved models and intermediate artefacts.\n",
    "        \"\"\"\n",
    "        self._run_dir = model_dir / \"gensim_lda_runs\"\n",
    "        self._run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def paths(self, label: str) -> tuple[Path, Path, Path]:\n",
    "        \"\"\"\n",
    "        Get artefact paths for a run label.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        label\n",
    "            Run label.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[pathlib.Path, pathlib.Path, pathlib.Path]\n",
    "            (dict_path, corpus_path, model_path)\n",
    "        \"\"\"\n",
    "        dict_path = self._run_dir / f\"{label}_dictionary.dict\"\n",
    "        corpus_path = self._run_dir / f\"{label}_corpus.mm\"\n",
    "        model_path = self._run_dir / f\"{label}_lda_model.gensim\"\n",
    "        return dict_path, corpus_path, model_path\n",
    "\n",
    "    def save_dictionary(self, dictionary: corpora.Dictionary, path: Path) -> None:\n",
    "        dictionary.save(str(path))\n",
    "\n",
    "    def save_corpus(self, corpus: list[list[tuple[int, int]]], path: Path) -> None:\n",
    "        MmCorpus.serialize(str(path), corpus)\n",
    "\n",
    "    def save_model(self, model: LdaModel, path: Path) -> None:\n",
    "        model.save(str(path))\n",
    "\n",
    "    def load_model(self, path: Path) -> LdaModel:\n",
    "        return LdaModel.load(str(path))\n",
    "\n",
    "\n",
    "class LDATrainer:\n",
    "    \"\"\"Train a Gensim LDA model.\"\"\"\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        *,\n",
    "        corpus: list[list[tuple[int, int]]],\n",
    "        dictionary: corpora.Dictionary,\n",
    "        config: LDAConfig,\n",
    "    ) -> LdaModel:\n",
    "        return LdaModel(\n",
    "            corpus=corpus,\n",
    "            id2word=dictionary,\n",
    "            num_topics=config.num_topics,\n",
    "            passes=config.passes,\n",
    "            chunksize=config.chunksize,\n",
    "            iterations=config.iterations,\n",
    "            random_state=config.seed,\n",
    "            eval_every=config.eval_every,\n",
    "            alpha=config.alpha,\n",
    "            eta=config.eta,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class LDAEvaluator:\n",
    "    \"\"\"Compute topic summaries and coherence for an LDA model.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _total_tokens(corpus: list[list[tuple[int, int]]]) -> int:\n",
    "        return int(sum(cnt for doc in corpus for _, cnt in doc))\n",
    "\n",
    "    @staticmethod\n",
    "    def _as_vis_dict(vis: Any) -> dict[str, Any]:\n",
    "        if hasattr(vis, \"to_dict\"):\n",
    "            return vis.to_dict()\n",
    "        if isinstance(vis, dict):\n",
    "            return vis\n",
    "        raise TypeError(\"Expected a pyLDAvis PreparedData object or dict-like representation.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _top_terms_from_tinfo(\n",
    "        tinfo: pd.DataFrame,\n",
    "        *,\n",
    "        topic_num: int,\n",
    "        top_n: int,\n",
    "        lambda_val: float,\n",
    "    ) -> list[str]:\n",
    "        \"\"\"\n",
    "        Compute LDAvis relevance ranking for a given topic.\n",
    "\n",
    "        LDAvis relevance (Sievert & Shirley) uses:\n",
    "        relevance = lambda * logprob + (1 - lambda) * loglift\n",
    "        \"\"\"\n",
    "        df_t = tinfo[tinfo[\"Category\"] == f\"Topic{topic_num}\"].copy()\n",
    "        if df_t.empty:\n",
    "            return []\n",
    "\n",
    "        df_t[\"relevance\"] = (lambda_val * df_t[\"logprob\"]) + ((1 - lambda_val) * df_t[\"loglift\"])\n",
    "        df_t = df_t.sort_values(\"relevance\", ascending=False)\n",
    "        return df_t[\"Term\"].head(top_n).astype(str).tolist()\n",
    "\n",
    "    @staticmethod\n",
    "    def _dominant_topic_counts(\n",
    "        model: LdaModel,\n",
    "        corpus: list[list[tuple[int, int]]],\n",
    "    ) -> dict[int, int]:\n",
    "        \"\"\"\n",
    "        Count documents (reviews) by dominant topic.\n",
    "\n",
    "        Returns a mapping keyed by pyLDAvis topic numbering (1..K).\n",
    "        \"\"\"\n",
    "        counts: dict[int, int] = {}\n",
    "        for bow in corpus:\n",
    "            topic_probs = model.get_document_topics(bow, minimum_probability=0.0)\n",
    "            dominant_topic = max(topic_probs, key=lambda x: x[1])[0]  # 0-based\n",
    "            topic_vis = int(dominant_topic) + 1  # pyLDAvis is 1-based\n",
    "            counts[topic_vis] = counts.get(topic_vis, 0) + 1\n",
    "        return counts\n",
    "\n",
    "    def topic_table(\n",
    "        self,\n",
    "        model: LdaModel,\n",
    "        *,\n",
    "        top_n_words: int,\n",
    "        vis: Any,\n",
    "        corpus: list[list[tuple[int, int]]],\n",
    "        coherence_cv: float,\n",
    "        lambda_alt: float = 0.1,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Build a topic summary table, ranked by document count.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - TopicId matches pyLDAvis numbering (1..K).\n",
    "        - Topic is 1..K after sorting by Count (largest first).\n",
    "        - Count is document-level (dominant topic per review).\n",
    "        \"\"\"\n",
    "        vis_d = self._as_vis_dict(vis)\n",
    "\n",
    "        mds = pd.DataFrame(vis_d[\"mdsDat\"])\n",
    "        tinfo = pd.DataFrame(vis_d[\"tinfo\"])\n",
    "\n",
    "        if \"topics\" not in mds.columns or \"Freq\" not in mds.columns:\n",
    "            raise KeyError(\"pyLDAvis mdsDat is missing expected columns ('topics', 'Freq').\")\n",
    "\n",
    "        doc_counts = self._dominant_topic_counts(model, corpus)\n",
    "\n",
    "        rows: list[dict[str, Any]] = []\n",
    "        for topic_num in range(1, model.num_topics + 1):\n",
    "            count_docs = int(doc_counts.get(int(topic_num), 0))\n",
    "\n",
    "            top_l1 = self._top_terms_from_tinfo(\n",
    "                tinfo,\n",
    "                topic_num=topic_num,\n",
    "                top_n=top_n_words,\n",
    "                lambda_val=1.0,\n",
    "            )\n",
    "            top_lalt = self._top_terms_from_tinfo(\n",
    "                tinfo,\n",
    "                topic_num=topic_num,\n",
    "                top_n=top_n_words,\n",
    "                lambda_val=float(lambda_alt),\n",
    "            )\n",
    "\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"TopicId\": int(topic_num),\n",
    "                    \"Count\": count_docs,\n",
    "                    \"TopWords_lambda_1_0\": \", \".join(top_l1),\n",
    "                    \"TopWords_lambda_0_1\": \", \".join(top_lalt),\n",
    "                    \"Coherence_c_v\": float(coherence_cv),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        df = (\n",
    "            pd.DataFrame(rows)\n",
    "            .sort_values([\"Count\", \"TopicId\"], ascending=[False, True])\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        df.insert(0, \"Topic\", range(1, len(df) + 1))\n",
    "        df = df[[\"Topic\", \"TopicId\", \"Count\", \"TopWords_lambda_1_0\", \"TopWords_lambda_0_1\", \"Coherence_c_v\"]]\n",
    "        return df\n",
    "\n",
    "    def coherence_cv(\n",
    "        self,\n",
    "        *,\n",
    "        model: LdaModel,\n",
    "        tokens: list[list[str]],\n",
    "        dictionary: corpora.Dictionary,\n",
    "    ) -> float:\n",
    "        coherence_model = CoherenceModel(model=model, texts=tokens, dictionary=dictionary, coherence=\"c_v\")\n",
    "        return float(coherence_model.get_coherence())\n",
    "\n",
    "\n",
    "class LDAVizWriter:\n",
    "    \"\"\"Create and persist pyLDAvis artefacts.\"\"\"\n",
    "\n",
    "    def build(self, model: LdaModel, corpus: list[list[tuple[int, int]]], dictionary: corpora.Dictionary) -> Any:\n",
    "        return gensimvis.prepare(model, corpus, dictionary)\n",
    "\n",
    "    def save_html(self, vis: Any, path: Path) -> None:\n",
    "        pyLDAvis.save_html(vis, str(path))\n",
    "\n",
    "\n",
    "class LDARunner:\n",
    "    \"\"\"\n",
    "    Orchestrate an end-to-end LDA run (build, train/load, evaluate, export).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Output naming convention:\n",
    "    - {label}_dictionary.dict\n",
    "    - {label}_corpus.mm\n",
    "    - {label}_lda_model.gensim\n",
    "    - {label}_gensim_lda_topics.csv\n",
    "    - {label}_gensim_lda_intertopic_map.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: LDAConfig,\n",
    "        *,\n",
    "        tokeniser: Any,\n",
    "        builder: Any,\n",
    "        store: Optional[LDAArtefactStore] = None,\n",
    "        trainer: Optional[LDATrainer] = None,\n",
    "        evaluator: Optional[LDAEvaluator] = None,\n",
    "        viz: Optional[LDAVizWriter] = None,\n",
    "    ) -> None:\n",
    "        self.cfg = config\n",
    "        np.random.seed(self.cfg.seed)\n",
    "\n",
    "        self.tokeniser = tokeniser\n",
    "        self.builder = builder\n",
    "        self.store = store or LDAArtefactStore(self.cfg.model_dir)\n",
    "        self.trainer = trainer or LDATrainer()\n",
    "        self.evaluator = evaluator or LDAEvaluator()\n",
    "        self.viz = viz or LDAVizWriter()\n",
    "\n",
    "    def run(self, *, tokens: list[list[str]], label: str, show_vis: bool = True) -> LDARunResult:\n",
    "        if len(tokens) == 0:\n",
    "            raise ValueError(f\"{label}: no documents after cleaning/tokenisation.\")\n",
    "\n",
    "        dict_path, corpus_path, model_path = self.store.paths(label)\n",
    "\n",
    "        dictionary = self.builder.build_dictionary(tokens, no_below=self.cfg.no_below, no_above=self.cfg.no_above)\n",
    "        corpus = self.builder.build_bow(tokens, dictionary)\n",
    "\n",
    "        if len(dictionary) == 0 or len(corpus) == 0:\n",
    "            raise ValueError(\n",
    "                f\"{label}: corpus/dictionary empty. Try relaxing no_below/no_above or check preprocessing.\"\n",
    "            )\n",
    "\n",
    "        self.store.save_dictionary(dictionary, dict_path)\n",
    "        self.store.save_corpus(corpus, corpus_path)\n",
    "\n",
    "        if self.cfg.train_new_model:\n",
    "            model = self.trainer.train(corpus=corpus, dictionary=dictionary, config=self.cfg)\n",
    "            self.store.save_model(model, model_path)\n",
    "        else:\n",
    "            model = self.store.load_model(model_path)\n",
    "\n",
    "        coherence_cv = self.evaluator.coherence_cv(model=model, tokens=tokens, dictionary=dictionary)\n",
    "\n",
    "        vis = self.viz.build(model, corpus, dictionary)\n",
    "        vis_path = self.cfg.plot_dir / f\"{label}_gensim_lda_intertopic_map.html\"\n",
    "        self.viz.save_html(vis, vis_path)\n",
    "\n",
    "        # Topic table aligned to pyLDAvis topic numbering \n",
    "        # Count is now document-level (dominant topic per review).\n",
    "        topics_table = self.evaluator.topic_table(\n",
    "            model,\n",
    "            top_n_words=self.cfg.top_n_words,\n",
    "            vis=vis,\n",
    "            corpus=corpus,\n",
    "            coherence_cv=coherence_cv,\n",
    "            lambda_alt=0.1,\n",
    "        )\n",
    "\n",
    "        topics_csv = self.cfg.table_dir / f\"{label}_gensim_lda_topics.csv\"\n",
    "        topics_table.to_csv(topics_csv, index=False)\n",
    "\n",
    "        result = LDARunResult(\n",
    "            label=label,\n",
    "            model_path=model_path,\n",
    "            dict_path=dict_path,\n",
    "            corpus_path=corpus_path,\n",
    "            topics_csv=topics_csv,\n",
    "            vis_path=vis_path,\n",
    "            coherence_cv=coherence_cv,\n",
    "            topics_table=topics_table,\n",
    "            vis=vis,\n",
    "        )\n",
    "\n",
    "        print(\"Saved:\", result.topics_csv)\n",
    "        print(\"Saved:\", result.vis_path)\n",
    "        print(\"Coherence (c_v):\", round(result.coherence_cv, 4))\n",
    "        display(result.topics_table)\n",
    "\n",
    "        if show_vis:\n",
    "            display(HTML(pyLDAvis.prepared_data_to_html(result.vis)))\n",
    "\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def summary_row(result: LDARunResult) -> dict[str, Any]:\n",
    "        return {\n",
    "            \"Label\": result.label,\n",
    "            \"TopicsCSV\": str(result.topics_csv),\n",
    "            \"VisHTML\": str(result.vis_path),\n",
    "            \"Coherence_c_v\": result.coherence_cv,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef5921",
   "metadata": {},
   "outputs": [],
   "source": [
    "TokenNormaliser = Callable[[str], list[str]]\n",
    "\n",
    "class PreprocessedTokeniser:\n",
    "    \"\"\"Tokenise preprocessed text into token lists.\"\"\"\n",
    "\n",
    "    def __init__(self, *, normaliser: Optional[TokenNormaliser] = None) -> None:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        normaliser\n",
    "            Optional token normaliser applied per whitespace token.\n",
    "            If None, tokens are returned unchanged (whitespace split only).\n",
    "        \"\"\"\n",
    "        self._normaliser = normaliser\n",
    "        self._ws_re = re.compile(r\"\\s+\")\n",
    "\n",
    "    def transform(self, series: pd.Series) -> list[list[str]]:\n",
    "        \"\"\"\n",
    "        Convert a Series of strings into token lists.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        series\n",
    "            Series containing preprocessed text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[list[str]]\n",
    "            Token lists, one per non-empty document.\n",
    "        \"\"\"\n",
    "        texts = series.fillna(\"\").astype(str).str.strip()\n",
    "        texts = texts.loc[texts.ne(\"\")]\n",
    "        texts = texts.str.replace(self._ws_re, \" \", regex=True).str.strip()\n",
    "\n",
    "        docs: list[list[str]] = []\n",
    "        for text in texts.tolist():\n",
    "            raw_tokens = text.split()\n",
    "\n",
    "            if self._normaliser is None:\n",
    "                doc_tokens = raw_tokens\n",
    "            else:\n",
    "                doc_tokens = []\n",
    "                for tok in raw_tokens:\n",
    "                    doc_tokens.extend(self._normaliser(tok))\n",
    "\n",
    "            if doc_tokens:\n",
    "                docs.append(doc_tokens)\n",
    "\n",
    "        return docs\n",
    "\n",
    "    def describe(self, label: str, tokens: list[list[str]]) -> None:\n",
    "        \"\"\"\n",
    "        Print summary statistics for a tokenised corpus.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        label\n",
    "            Short label for printed output.\n",
    "        tokens\n",
    "            Tokenised documents.\n",
    "        \"\"\"\n",
    "        doc_count = len(tokens)\n",
    "        total_tokens = sum(len(t) for t in tokens)\n",
    "        avg_len = total_tokens / doc_count if doc_count else 0\n",
    "        print(f\"{label}: docs={doc_count:,} total_tokens={total_tokens:,} avg_doc_len={avg_len:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa2ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GensimCorpusBuilder:\n",
    "    \"\"\"Build a Gensim dictionary and BoW corpus from tokenised documents.\"\"\"\n",
    "\n",
    "    def build_dictionary(self, tokens: list[list[str]], *, no_below: int, no_above: float) -> corpora.Dictionary:\n",
    "        \"\"\"\n",
    "        Create and filter a Gensim dictionary.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tokens\n",
    "            Tokenised documents.\n",
    "        no_below\n",
    "            Minimum document frequency threshold.\n",
    "        no_above\n",
    "            Maximum document frequency fraction threshold.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        gensim.corpora.Dictionary\n",
    "            Filtered dictionary.\n",
    "        \"\"\"\n",
    "        dictionary = corpora.Dictionary(tokens)\n",
    "        dictionary.filter_extremes(no_below=no_below, no_above=no_above)\n",
    "        return dictionary\n",
    "\n",
    "    def build_bow(self, tokens: list[list[str]], dictionary: corpora.Dictionary) -> list[list[tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Convert documents into BoW count vectors.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tokens\n",
    "            Tokenised documents.\n",
    "        dictionary\n",
    "            Token-id mapping.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[list[tuple[int, int]]]\n",
    "            BoW corpus in (token_id, count) format.\n",
    "        \"\"\"\n",
    "        return [dictionary.doc2bow(doc) for doc in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe583c",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9578554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads CSVs\n",
    "df_preprocessed = load_csv(PREPROCESSED_PATH)\n",
    "df_preprocessed_negative = load_csv(PREPROCESSED_NEG_PATH)\n",
    "df_preprocessed_negative_emotion = load_csv(PREPROCESSED_NEG_EMO_PATH)\n",
    "\n",
    "print(\"df_preprocessed rows:\", len(df_preprocessed))\n",
    "print(\"df_preprocessed_negative rows:\", len(df_preprocessed_negative))\n",
    "print(\"df_preprocessed_negative_emotion rows:\", len(df_preprocessed_negative_emotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fffe243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA settings\n",
    "\n",
    "TRAIN_NEW_MODEL = True  # If True, trains a fresh LDA model and overwrites saved artefacts\n",
    "\n",
    "NUM_TOPICS = 5      # Number of latent topics (K) - lower creates broader topics\n",
    "PASSES = 10         # Number of full epochs over the whole corpus\n",
    "CHUNKSIZE = 100     # Documents processed per training chunk\n",
    "ITERATIONS = 1000    # Higher to improve stability/convergence but increase runtime.\n",
    "EVAL_EVERY = None   # None disables evaluation (faster).\n",
    "\n",
    "NO_BELOW = 10       # drop tokens that appear in fewer than this many documents (removes rare noise terms).\n",
    "NO_ABOVE = 0.25      #  drop tokens that appear in more than this fraction of documents (removes very common terms).\n",
    "TOP_N_WORDS = 5   #  how many top words per topic to export/display (does not affect model training).\n",
    "\n",
    "ALPHA = \"asymmetric\"    # Document-topic prior. Lower/more uneven values encourage fewer topics per document and can reduce topic mixing.\n",
    "ETA = \"auto\"            # Topic-word prior. Lower values encourage sharper, more distinctive topic vocabularies; \"auto\" learns this from data.\n",
    "\n",
    "print(\"TRAIN_NEW_MODEL:\", TRAIN_NEW_MODEL)\n",
    "print(\"NUM_TOPICS:\", NUM_TOPICS)\n",
    "print(\"NO_BELOW / NO_ABOVE:\", NO_BELOW, NO_ABOVE)\n",
    "print(\"ALPHA:\", ALPHA)\n",
    "print(\"ETA:\", ETA)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4309a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = PreprocessedTokeniser()\n",
    "builder = GensimCorpusBuilder()\n",
    "\n",
    "lda_cfg = LDAConfig(\n",
    "    seed=SEED,\n",
    "    train_new_model=TRAIN_NEW_MODEL,\n",
    "    num_topics=NUM_TOPICS,\n",
    "    passes=PASSES,\n",
    "    chunksize=CHUNKSIZE,\n",
    "    iterations=ITERATIONS,\n",
    "    eval_every=EVAL_EVERY,\n",
    "    no_below=NO_BELOW,\n",
    "    no_above=NO_ABOVE,\n",
    "    top_n_words=TOP_N_WORDS,\n",
    "    plot_dir=PLOT_DIR,\n",
    "    table_dir=TABLE_DIR,\n",
    "    model_dir=MODEL_DIR,\n",
    "    alpha=ALPHA,\n",
    "    eta=ETA,\n",
    ")\n",
    "\n",
    "lda_runner = LDARunner(lda_cfg, tokeniser=tokeniser, builder=builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52122a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_negative = lda_runner.tokeniser.transform(df_preprocessed_negative[TEXT_COL])\n",
    "lda_runner.tokeniser.describe(\"NEG\", tokens_negative)\n",
    "result_negative = lda_runner.run(tokens=tokens_negative, label=\"lda_preprocessed_negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef5e2e",
   "metadata": {},
   "source": [
    "### Run Emotion Subsets on Negative Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f5d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA settings\n",
    "\n",
    "TRAIN_NEW_MODEL = True \n",
    "\n",
    "NUM_TOPICS = 3      \n",
    "PASSES = 10        \n",
    "CHUNKSIZE = 100     \n",
    "ITERATIONS = 1000    \n",
    "EVAL_EVERY = None   \n",
    "\n",
    "NO_BELOW = 10       \n",
    "NO_ABOVE = 0.3     \n",
    "TOP_N_WORDS = 5   \n",
    "\n",
    "ALPHA = \"asymmetric\"    \n",
    "ETA = \"auto\"           \n",
    "\n",
    "print(\"TRAIN_NEW_MODEL:\", TRAIN_NEW_MODEL)\n",
    "print(\"NUM_TOPICS:\", NUM_TOPICS)\n",
    "print(\"NO_BELOW / NO_ABOVE:\", NO_BELOW, NO_ABOVE)\n",
    "print(\"ALPHA:\", ALPHA)\n",
    "print(\"ETA:\", ETA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d19c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_cfg = LDAConfig(\n",
    "    seed=SEED,\n",
    "    train_new_model=TRAIN_NEW_MODEL,\n",
    "    num_topics=NUM_TOPICS,\n",
    "    passes=PASSES,\n",
    "    chunksize=CHUNKSIZE,\n",
    "    iterations=ITERATIONS,\n",
    "    eval_every=EVAL_EVERY,\n",
    "    no_below=NO_BELOW,\n",
    "    no_above=NO_ABOVE,\n",
    "    top_n_words=TOP_N_WORDS,\n",
    "    plot_dir=PLOT_DIR,\n",
    "    table_dir=TABLE_DIR,\n",
    "    model_dir=MODEL_DIR,\n",
    "    alpha=ALPHA,\n",
    "    eta=ETA,\n",
    ")\n",
    "\n",
    "lda_runner = LDARunner(lda_cfg, tokeniser=tokeniser, builder=builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_emotion_subset(emotion: str) -> LDARunResult:\n",
    "    df_sub = df_preprocessed_negative_emotion[df_preprocessed_negative_emotion[EMOTION_COL] == emotion].copy()\n",
    "    print(f\"Negative emotion rows ({emotion}):\", len(df_sub))\n",
    "    tokens = lda_runner.tokeniser.transform(df_sub[TEXT_COL])\n",
    "    lda_runner.tokeniser.describe(emotion.upper(), tokens)\n",
    "    return lda_runner.run(tokens=tokens, label=f\"lda_preprocessed_negative_emotion_{emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dadc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_neg_sadness = run_emotion_subset(\"sadness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_rows = [\n",
    "    lda_runner.summary_row(result_negative),\n",
    "    lda_runner.summary_row(result_neg_sadness)\n",
    "]\n",
    "\n",
    "df_summary = pd.DataFrame(summary_rows)\n",
    "display(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e30f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_s = time.perf_counter() - NOTEBOOK_T0\n",
    "elapsed_m = elapsed_s / 60\n",
    "print(f\"\\nTotal runtime: {elapsed_s:,.1f} seconds ({elapsed_m:,.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d9d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_s_global = time.perf_counter() - NOTEBOOK_T0_GLOBAL\n",
    "elapsed_m_global = elapsed_s_global / 60\n",
    "\n",
    "print(f\"\\nFull notebook total runtime: {elapsed_s_global:,.1f} seconds ({elapsed_m_global:,.2f} minutes)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1b3BQPwpdeenJ_MKBJavHO9yRCD6FBth3",
     "timestamp": 1725194341012
    },
    {
     "file_id": "1TR3h6zrLLaBD-hIaJVzoKaom_isIt0oD",
     "timestamp": 1724858405862
    },
    {
     "file_id": "1rwnNnduXRghHplyunqWVcyJQW5pz3nOy",
     "timestamp": 1724238923684
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "004804406af84175a09dced3a520943b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07b167d7f08d4f3abe13680e9e91454e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b8ff4e464e240d0a26ddc8d22978f33",
      "placeholder": "​",
      "style": "IPY_MODEL_4ed097c2b1be4321ab541d659b8bd478",
      "value": " 935/935 [00:00&lt;00:00, 82.2kB/s]"
     }
    },
    "0bfdf7f78113490b8d6d8946d85421d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49f5421603de482f95fd33294bbb949b",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8384dbf29a0643868cfc8ee53f8a7ba0",
      "value": 231508
     }
    },
    "13e28424f7734553b62467a2e1bb6917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1dc7deed51154716a6e0f83e382e048e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21cc2093d91f4ea8924346f7f187c39d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "222c642d2f5f4716acbc4fd0d42fc5bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_feceb8cc56cf4503af79ea961c1551c0",
       "IPY_MODEL_0bfdf7f78113490b8d6d8946d85421d1",
       "IPY_MODEL_f9a69b61eb434098aa69c7dcc5b6e887"
      ],
      "layout": "IPY_MODEL_c780f1ff9fff45bc889c4d3d99a855ff"
     }
    },
    "27d8155d54a7477aac2ca8c58d11ecfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e16a3f04851a4499bba2b30de625a510",
      "placeholder": "​",
      "style": "IPY_MODEL_13e28424f7734553b62467a2e1bb6917",
      "value": " 285/285 [00:00&lt;00:00, 24.7kB/s]"
     }
    },
    "2a92f06b672c4b38ae2117296f4bac95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "360343eaac314ede9e3b351da8a5d60a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b737fb62306546db8e6c70df474f4dca",
       "IPY_MODEL_46bf93f843e0474d9760b1242b9d274d",
       "IPY_MODEL_07b167d7f08d4f3abe13680e9e91454e"
      ],
      "layout": "IPY_MODEL_d9d2f2c58f274e3580cfe445925a921f"
     }
    },
    "3c90b7113afb4ed7ade40eb101fb0bb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46bf93f843e0474d9760b1242b9d274d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0ae937349b847e9ba1387b402e9cf58",
      "max": 935,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_beafee1481af441595e254ccb2ca21f8",
      "value": 935
     }
    },
    "48ba6828f8cb4d8cb0460e8c4d98826e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49f5421603de482f95fd33294bbb949b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ed097c2b1be4321ab541d659b8bd478": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50970208aa654b21b46443e1ea66c6bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "591b5badc54a4f0e9158723714a35d99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc6636734eb14095b92fe68522a320b6",
       "IPY_MODEL_ee35483296a945eab4d2ab4219c6de79",
       "IPY_MODEL_27d8155d54a7477aac2ca8c58d11ecfb"
      ],
      "layout": "IPY_MODEL_5adec51fb21240d5a513d87533c19804"
     }
    },
    "5adec51fb21240d5a513d87533c19804": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67dfc52cf2224a9a80013a66c6b25f50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_788161b2bb7a4b3593b5adc972f2bbe8",
      "placeholder": "​",
      "style": "IPY_MODEL_af5e9c14b0da4022a019ba095b6c3b1a",
      "value": " 466k/466k [00:00&lt;00:00, 31.3MB/s]"
     }
    },
    "6a69a20a3caa4852a99b759dc52c603c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e4dec9ef21f4dc3afe8613282f34ce8",
       "IPY_MODEL_8107133b0b524bd593e48153ca4eeb3b",
       "IPY_MODEL_9d949220d30e4c959b379831a32ba75f"
      ],
      "layout": "IPY_MODEL_941e7a71767248b79470a13ea14e99c3"
     }
    },
    "7838303da2d14668b4a5487fd3726668": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84d9ebd8c2874e4e9d058cfae56b4f76",
      "placeholder": "​",
      "style": "IPY_MODEL_3c90b7113afb4ed7ade40eb101fb0bb0",
      "value": " 438M/438M [00:27&lt;00:00, 14.3MB/s]"
     }
    },
    "788161b2bb7a4b3593b5adc972f2bbe8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ba363b7faff43a3b0adbfc281ef9137": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dc7deed51154716a6e0f83e382e048e",
      "max": 437975140,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e187b2cf690f44b595c2501d43351397",
      "value": 437975140
     }
    },
    "8107133b0b524bd593e48153ca4eeb3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba196951590c46b9ad74bf7897cdcf76",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9b9401dd276e4e32a317acb2b3ed6f54",
      "value": 112
     }
    },
    "81932317d1c145ab8e7d001fbe8a46f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8384dbf29a0643868cfc8ee53f8a7ba0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "84d9ebd8c2874e4e9d058cfae56b4f76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91beeb38d1f84f0ea44377e5078104a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce9a6259b014404d8785516cdf16ad56",
       "IPY_MODEL_a0afbe0812544ccabdca5d3f2e031a16",
       "IPY_MODEL_67dfc52cf2224a9a80013a66c6b25f50"
      ],
      "layout": "IPY_MODEL_95981efb427d4735886ea7fbab0f04de"
     }
    },
    "941e7a71767248b79470a13ea14e99c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95981efb427d4735886ea7fbab0f04de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "980ac9c2d87a43e6a565ae01ab927b72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b8ff4e464e240d0a26ddc8d22978f33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b9401dd276e4e32a317acb2b3ed6f54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d949220d30e4c959b379831a32ba75f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7296f48f9304299bd6638df79a51e6b",
      "placeholder": "​",
      "style": "IPY_MODEL_48ba6828f8cb4d8cb0460e8c4d98826e",
      "value": " 112/112 [00:00&lt;00:00, 9.82kB/s]"
     }
    },
    "9e4dec9ef21f4dc3afe8613282f34ce8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a60f3be522214308846eb44f66fd8b1b",
      "placeholder": "​",
      "style": "IPY_MODEL_b84c942040ac4af18c5c1b8da4518e45",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "a0afbe0812544ccabdca5d3f2e031a16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_980ac9c2d87a43e6a565ae01ab927b72",
      "max": 466248,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6461959823a4e5aa4e73f9384003983",
      "value": 466248
     }
    },
    "a60f3be522214308846eb44f66fd8b1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6304a3655884d909dbaed69f1c1405f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7296f48f9304299bd6638df79a51e6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a75fb509af434fc8bbed5bd44bb24514": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8507bb965a3463181a9830c98fff71e",
      "placeholder": "​",
      "style": "IPY_MODEL_a6304a3655884d909dbaed69f1c1405f",
      "value": "model.safetensors: 100%"
     }
    },
    "a8507bb965a3463181a9830c98fff71e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af5e9c14b0da4022a019ba095b6c3b1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b737fb62306546db8e6c70df474f4dca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b86427ea33c1497896595add96cc55dc",
      "placeholder": "​",
      "style": "IPY_MODEL_c51385f0704341148acd0384da57a2fa",
      "value": "config.json: 100%"
     }
    },
    "b84c942040ac4af18c5c1b8da4518e45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b86427ea33c1497896595add96cc55dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba196951590c46b9ad74bf7897cdcf76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "beafee1481af441595e254ccb2ca21f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c0ae937349b847e9ba1387b402e9cf58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c51385f0704341148acd0384da57a2fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c780f1ff9fff45bc889c4d3d99a855ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd06135c9bfc437b913008d8723b9a33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ce9a6259b014404d8785516cdf16ad56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdc3f69f26aa4007bb9b76ee297bf096",
      "placeholder": "​",
      "style": "IPY_MODEL_21cc2093d91f4ea8924346f7f187c39d",
      "value": "tokenizer.json: 100%"
     }
    },
    "d0a502c357c6429f9c2515b9d06672c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5356e37e061426882d6f62b8614eb2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9d2f2c58f274e3580cfe445925a921f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e16a3f04851a4499bba2b30de625a510": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e187b2cf690f44b595c2501d43351397": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e9fee4e0cb794d3493b7478601880a1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee35483296a945eab4d2ab4219c6de79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5356e37e061426882d6f62b8614eb2c",
      "max": 285,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd06135c9bfc437b913008d8723b9a33",
      "value": 285
     }
    },
    "ee3cf348ca0d40bfaa27bb3ada1872bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5ce90ddcdb745ee8a19a4c056122724": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a75fb509af434fc8bbed5bd44bb24514",
       "IPY_MODEL_7ba363b7faff43a3b0adbfc281ef9137",
       "IPY_MODEL_7838303da2d14668b4a5487fd3726668"
      ],
      "layout": "IPY_MODEL_d0a502c357c6429f9c2515b9d06672c1"
     }
    },
    "f6461959823a4e5aa4e73f9384003983": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f9a69b61eb434098aa69c7dcc5b6e887": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9fee4e0cb794d3493b7478601880a1b",
      "placeholder": "​",
      "style": "IPY_MODEL_2a92f06b672c4b38ae2117296f4bac95",
      "value": " 232k/232k [00:00&lt;00:00, 17.4MB/s]"
     }
    },
    "fc6636734eb14095b92fe68522a320b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_004804406af84175a09dced3a520943b",
      "placeholder": "​",
      "style": "IPY_MODEL_81932317d1c145ab8e7d001fbe8a46f4",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "fdc3f69f26aa4007bb9b76ee297bf096": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "feceb8cc56cf4503af79ea961c1551c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50970208aa654b21b46443e1ea66c6bd",
      "placeholder": "​",
      "style": "IPY_MODEL_ee3cf348ca0d40bfaa27bb3ada1872bb",
      "value": "vocab.txt: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

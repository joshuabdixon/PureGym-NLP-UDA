{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07_topic_modelling_falcon\n",
    "\n",
    "This notebook uses an instruction-tuned large language model (Falcon) to extract concise topics from negative Trustpilot reviews, and then applies BERTopic to cluster and summarise those extracted topics. The main steps are:\n",
    "\n",
    "* Loading the raw filtered review dataset and filtering to negative reviews using rating thresholds defined in the project configuration.\n",
    "\n",
    "* Optionally sub-sampling the negative reviews for faster experimentation (`SAMPLE_SIZE`), while keeping sampling reproducible via a fixed random seed.\n",
    "\n",
    "* Running batched topic extraction with the Hugging Face text-generation pipeline using **Falcon-H1-1.5B-Instruct** (`tiiuae/Falcon-H1-1.5B-Instruct`), constrained by:\n",
    "\n",
    "  * a fixed prompt template\n",
    "\n",
    "  * maximum input length (`MAX_INPUT_TOKENS`)\n",
    "\n",
    "  * deterministic decoding (greedy generation with `DO_SAMPLE=False`) for reproducibility\n",
    "\n",
    "* Preprocessing (using `TextPreproccessor`), parsing and normalising the generated output to extract exactly three short topics per review and filtering out rows with empty or invalid extractions.\n",
    "\n",
    "* Saving the generated topics and cleaned topic strings as CSV outputs for reporting and downstream modelling.\n",
    "\n",
    "* Fitting BERTopic (using `BERTopicRunner`) on the cleaned and preprocessed LLM-generated topic strings to identify recurring themes and produce topic-level summaries and visualisations.\n",
    "\n",
    "The notebook saves outputs to the configured directories:\n",
    "\n",
    "* Extracted topics and filtered results (CSV): `output/tables/07_topic_modelling_falcon/`\n",
    "\n",
    "* BERTopic plots (PNG/HTML where applicable): `output/plots/07_topic_modelling_falcon/`\n",
    "\n",
    "* Saved BERTopic models: `output/models/07_topic_modelling_falcon/`\n",
    "\n",
    "All experiments were run locally on a MacBook Pro (16-inch, Nov 2024) equipped with an Apple M4 Pro chip (14 CPU cores: 10 performance and 4 efficiency cores) and 24 GB of unified memory, running macOS Tahoe 26.2. Model inference was executed locally; where available, the pipeline can use Apple Silicon acceleration via MPS, otherwise it falls back to CPU. No distributed computing frameworks (e.g. SLURM or OpenPBS) were used. **The notebook has been tested on CPU and Apple Silicon (MPS); CUDA support is included for completeness but has not been validated in this project.**\n",
    "\n",
    "The notebook is implemented in Python and relies primarily on pandas, numpy, PyTorch, and Hugging Face Transformers (AutoTokenizer, AutoModelForCausalLM, and pipeline), alongside project-specific utilities for prompt-based topic extraction and BERTopic clustering. For reproducibility, a fixed random seed of **901** was used, and deterministic text generation settings were applied (greedy decoding).\n",
    "\n",
    "**Runtime:** On the above hardware, the notebook completes in approximately **4 hours** (MPS) when run on all negative reviews, with runtime dominated by LLM inference (tokenisation and generation). BERTopic clustering on the extracted topics typically adds a smaller additional cost relative to generation. It is recommended **SAMPLE_SIZE = 10** (increase if desired) is set for checking functionality for approximately **1min**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reproducibility note (BERTopic plots and top topics)**  \n",
    "\n",
    "* BERTopic visualisations in this notebook (for example intertopic distance maps) rely on a UMAP projection. UMAP can yield slightly different embeddings across hardware/OS and execution settings (particularly when parallelism differs), so plots generated on a different device from the one specified above may not exactly match the reported figures even when the same random seed is used. On the device used for this project, the plots are reproducible for the fixed seed (**901**).\n",
    "\n",
    "* This sensitivity to execution environment is one reason LDA was also explored in this project, as a complementary topic modelling approach with more straightforward reproducibility characteristics.\n",
    "\n",
    "* Documentation: https://umap-learn.readthedocs.io/en/latest/reproducibility.html\n",
    "\n",
    "* The reported plots are pre-saved in the folders for this reason. However, executing all notebooks will overwrite them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 10  # set None to run all rows\n",
    "\n",
    "IS_SAMPLE_RUN = SAMPLE_SIZE is not None\n",
    "SAVE_ARTIFACTS = not IS_SAMPLE_RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "NOTEBOOK_T0 = time.perf_counter()\n",
    "print(\"Notebook timer started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import ast\n",
    "from configparser import ConfigParser\n",
    "\n",
    "# Resolve project root as the parent of the folder the notebook is currently in\n",
    "CWD = Path.cwd().resolve()\n",
    "PROJECT_ROOT = CWD.parent\n",
    "\n",
    "# Safety fallback\n",
    "if not (PROJECT_ROOT / \"config.ini\").exists():\n",
    "    PROJECT_ROOT = next((p for p in (CWD, *CWD.parents) if (p / \"config.ini\").exists()), None)\n",
    "    if PROJECT_ROOT is None:\n",
    "        raise FileNotFoundError(\"Could not locate 'config.ini' in the current directory or its parents.\")\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "CONFIG = ConfigParser()\n",
    "CONFIG.read(PROJECT_ROOT / \"config.ini\")\n",
    "\n",
    "print(\"CONFIG used:\")\n",
    "for section in CONFIG.sections():\n",
    "    print(f\"\\n[{section}]\")\n",
    "    for key, value in CONFIG[section].items():\n",
    "        print(f\"{key} = {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "from utils.data_management.data_io import load_csv\n",
    "from modelling.bertopic.bertopic_runner import BERTopicRunner\n",
    "from utils.processing.text_preprocessor import TextPreprocessor\n",
    "\n",
    "\n",
    "DATA_DIR = (PROJECT_ROOT / CONFIG[\"DATA\"][\"DATA_DIR\"])\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_FILENAME_FILTERED = CONFIG[\"DATA\"][\"RAW_FILENAME_FILTERED\"]\n",
    "RAW_PATH_FILTERED = DATA_DIR / RAW_FILENAME_FILTERED\n",
    "\n",
    "TEXT_COL = CONFIG[\"FILTERING\"][\"TEXT_COL\"]\n",
    "NEGATIVE_RATINGS = ast.literal_eval(CONFIG[\"FILTERING\"].get(\"NEGATIVE_RATINGS\", \"[]\"))\n",
    "SEED = CONFIG[\"REPRODUCIBILITY\"].getint(\"SEED\")\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "TABLE_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"TABLE_DIR\"] / \"07_topic_modelling_falcon\"\n",
    "MODEL_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"MODEL_DIR\"] / \"07_topic_modelling_falcon\"\n",
    "PLOT_DIR = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"PLOT_DIR\"] / \"07_topic_modelling_falcon\"\n",
    "\n",
    "TABLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load raw filtered data and filter negative\n",
    "df_trustpilot = load_csv(str(RAW_PATH_FILTERED))\n",
    "print(\"Rows:\", len(df_trustpilot))\n",
    "print(\"Columns:\", df_trustpilot.columns.tolist())\n",
    "\n",
    "df_negative = df_trustpilot[df_trustpilot[\"Rating\"].isin(NEGATIVE_RATINGS)].copy()\n",
    "print(\"Negative rows:\", len(df_negative))\n",
    "\n",
    "df_work = df_negative\n",
    "if SAMPLE_SIZE is not None and len(df_work) > SAMPLE_SIZE:\n",
    "    df_work = df_work.sample(SAMPLE_SIZE, random_state=SEED)\n",
    "\n",
    "print(\"Working rows:\", len(df_work))\n",
    "display(df_work[[TEXT_COL, \"Rating\"]].head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Falcon Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "\n",
    "class FalconInitialiser:\n",
    "    \"\"\"Initialise tokenizer, model, and generation pipeline for instruction models.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def init_tokenizer(model_name: str) -> AutoTokenizer:\n",
    "        \"\"\"Load tokeniser and ensure a pad token is set.\"\"\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "        # Setting pad_token avoids warnings and helps with batched generation. Fall back with eos tokens.\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        return tokenizer\n",
    "\n",
    "    @staticmethod\n",
    "    def _has_mps() -> bool:\n",
    "        \"\"\"Check whether MPS is built and available.\"\"\"\n",
    "        return torch.backends.mps.is_built() and torch.backends.mps.is_available()\n",
    "\n",
    "    @staticmethod\n",
    "    def init_model(model_name: str) -> AutoModelForCausalLM:\n",
    "        \"\"\"Load model on the best available device.\"\"\"\n",
    "        # Prefer CUDA when available \n",
    "        if torch.cuda.is_available():\n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                dtype=torch.float16,  \n",
    "                device_map=\"auto\",\n",
    "                low_cpu_mem_usage=True,\n",
    "            )\n",
    "            model.eval()\n",
    "            return model\n",
    "\n",
    "        # Apple Silicon MPS (next preference))\n",
    "        if FalconInitialiser._has_mps():\n",
    "            # Try float16 first for speed/memory, fall back to float32\n",
    "            try:\n",
    "                model = AutoModelForCausalLM.from_pretrained(\n",
    "                    model_name,\n",
    "                    dtype=torch.float16,\n",
    "                    low_cpu_mem_usage=True,\n",
    "                ).to(\"mps\")\n",
    "            except Exception:\n",
    "                model = AutoModelForCausalLM.from_pretrained(\n",
    "                    model_name,\n",
    "                    dtype=torch.float32,\n",
    "                    low_cpu_mem_usage=True,\n",
    "                ).to(\"mps\")\n",
    "\n",
    "            model.eval()\n",
    "            return model\n",
    "\n",
    "        # Final fallback: CPU\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            low_cpu_mem_usage=True,\n",
    "        )\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def init_generator(model_name: str):\n",
    "        \"\"\"Create a Transformers text-generation pipeline.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            (generator, tokenizer) where generator is a text-generation pipeline.\n",
    "        \"\"\"\n",
    "\n",
    "        tokenizer = FalconInitialiser.init_tokenizer(model_name)\n",
    "        model = FalconInitialiser.init_model(model_name)\n",
    "\n",
    "        # Choose pipeline device argument based on what's available\n",
    "        # - CUDA: integer GPU index\n",
    "        # - MPS: \"mps\"\n",
    "        # - CPU: -1\n",
    "        if torch.cuda.is_available():\n",
    "            device = 0\n",
    "        elif FalconInitialiser._has_mps():\n",
    "            device = \"mps\"\n",
    "        else:\n",
    "            device = -1\n",
    "\n",
    "        # Build a text-generation pipeline for convenience (handles tokenisation + generation)\n",
    "        generator = pipeline(\n",
    "            task=\"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            return_full_text=False,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        return generator, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def _prompt_token_len(model_name: str, prompt: str) -> int:\n",
    "    tokenizer = FalconInitialiser.init_tokenizer(model_name)\n",
    "    return len(tokenizer.encode(prompt, add_special_tokens=False))\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FalconParams:\n",
    "    \"\"\"Configuration for topic extraction via an instruction model.\"\"\"\n",
    "\n",
    "    MODEL_NAME: str = \"tiiuae/Falcon-H1-1.5B-Instruct\"\n",
    "\n",
    "    # Batching\n",
    "    BATCH_SIZE: int = 64\n",
    "\n",
    "    # Generation controls\n",
    "    MAX_NEW_TOKENS: int = 30 # response tokens,\n",
    "    DO_SAMPLE: bool = False  # greedy decoding for reproducibility\n",
    "\n",
    "    # Only used when DO_SAMPLE=True\n",
    "    TEMPERATURE: Optional[float] = None\n",
    "    TOP_P: Optional[float] = None\n",
    "\n",
    "    # Output columns\n",
    "    RAW_COL: str = \"Generated Topics\"\n",
    "    EXTRACTED_COL: str = \"Extracted Topics\"\n",
    "\n",
    "    # Prompt\n",
    "    PROMPT: str = (\n",
    "        \"Extract the 3 main topics from this customer review.\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"- Return exactly 3 lines and stop.\\n\"\n",
    "        \"- Each line must be a short noun phrase (max 6 words).\\n\"\n",
    "        \"- No explanation, no extra text, no follow up questions.\\n\"\n",
    "        \"Format:\\n\"\n",
    "        \"1. <topic>\\n\"\n",
    "        \"2. <topic>\\n\"\n",
    "        \"3. <topic>\\n\\n\"\n",
    "        \"Review:\\n\"\n",
    "    )\n",
    "    # Keep 512 (see diagnostic in cell below) tokens for the review, plus however many tokens the prompt uses.\n",
    "    MAX_INPUT_TOKENS: int = 512 + _prompt_token_len(MODEL_NAME, PROMPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = FalconParams.MODEL_NAME\n",
    "generator, tokenizer = FalconInitialiser.init_generator(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token Length EDA\n",
    "RUN_TOKEN_LENGTH_DIAGNOSTICS = True \n",
    "if RUN_TOKEN_LENGTH_DIAGNOSTICS:\n",
    "    MAXLEN_CANDIDATES = [64, 96, 128, 160, 192, 256, 320, 384, 448, 512]\n",
    "    df_for_profile = df_negative \n",
    "\n",
    "    texts = (df_for_profile[TEXT_COL].fillna(\"\").astype(str).str.strip())\n",
    "    texts = texts.loc[texts.ne(\"\")]\n",
    "\n",
    "    # Compute token lengths without truncation for each tokeniser\n",
    "    token_lengths = texts.apply(lambda t: len(tokenizer.encode(t, add_special_tokens=True))).to_numpy()\n",
    "\n",
    "    # Worst-case length per text across both tokenisers (safe choice for later max_length)\n",
    "    token_lengths_worst = token_lengths\n",
    "\n",
    "    # % fully captured for each candidate max length\n",
    "    captured_pct = [(token_lengths <= L).mean() * 100 for L in MAXLEN_CANDIDATES]\n",
    "    captured_pct_worst = [(token_lengths_worst <= L).mean() * 100 for L in MAXLEN_CANDIDATES]\n",
    "\n",
    "    # Summary stats\n",
    "    percentiles = [50, 75, 90, 95, 97, 99]\n",
    "    pvals = np.percentile(token_lengths, percentiles)\n",
    "\n",
    "\n",
    "    p99 = float(np.percentile(token_lengths, 99))\n",
    "\n",
    "    print(\"Token length percentiles:\")\n",
    "    for p, v in zip(percentiles, pvals):\n",
    "        print(f\"{p:>2}%: {int(v)} tokens\")\n",
    "\n",
    "\n",
    "    print(f\"\\n99th percentile: {int(p99)} tokens\")\n",
    "\n",
    "    best_L = next((L for L, p in zip(MAXLEN_CANDIDATES, captured_pct_worst) if p >= 99), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAX_INPUT_TOKENS:\", FalconParams.MAX_INPUT_TOKENS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FalconBatchResult:\n",
    "    \"\"\"Container for batched generation results.\"\"\"\n",
    "    # Raw decoded text returned by the generation pipeline (one per input row)\n",
    "    raw_outputs: list[str]\n",
    "    # Parsed topics extracted from the raw output (one per input row)\n",
    "    extracted_topics: list[str]\n",
    "\n",
    "\n",
    "class FalconDataCompiler:\n",
    "    \"\"\"Apply an instruction model to extract 3 topics per row.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        df: pd.DataFrame,\n",
    "        text_col: str,\n",
    "        generator: Any,\n",
    "        tokenizer: Any,\n",
    "        prompt_template: str,\n",
    "        batch_size: int,\n",
    "        max_input_tokens: int,\n",
    "        max_new_tokens: int,\n",
    "        temperature: Optional[float],\n",
    "        top_p: Optional[float],\n",
    "        do_sample: bool,\n",
    "        raw_output_col: str,\n",
    "        topics_col: str,\n",
    "    ) -> None:\n",
    "        if text_col not in df.columns:\n",
    "            raise KeyError(f\"'{text_col}' not found in DataFrame\")\n",
    "\n",
    "        # Store core inputs\n",
    "        self._df = df\n",
    "        self._text_col = text_col\n",
    "\n",
    "        # Hugging Face text-generation pipeline and matching tokenizer\n",
    "        self._generator = generator\n",
    "        self._tokenizer = tokenizer\n",
    "\n",
    "        # Prompt template and batching controls\n",
    "        self._prompt_template = str(prompt_template)\n",
    "        self._batch_size = int(batch_size)\n",
    "\n",
    "        # Token budgets\n",
    "        # max_input_tokens controls how many tokens we allow in the full prompt+review\n",
    "        # max_new_tokens controls how many tokens the model is allowed to generate as output\n",
    "        self._max_input_tokens = int(max_input_tokens)\n",
    "        self._max_new_tokens = int(max_new_tokens)\n",
    "\n",
    "        # Whether to sample (stochastic decoding) or use greedy decoding (deterministic)\n",
    "        self._do_sample = bool(do_sample)\n",
    "\n",
    "        # Only keep sampling params when sampling is enabled \n",
    "        self._temperature: Optional[float] = float(temperature) if (self._do_sample and temperature is not None) else None\n",
    "        self._top_p: Optional[float] = float(top_p) if (self._do_sample and top_p is not None) else None\n",
    "\n",
    "        # Output column names\n",
    "        self._raw_output_col = str(raw_output_col)\n",
    "        self._topics_col = str(topics_col)\n",
    "\n",
    "        # Support both templates that include \"{review}\" and templates that do not (experimented both cases in development)\n",
    "        # If \"{review}\" exists, we split into prefix + suffix so we can token-budget just the review content\n",
    "        if \"{review}\" in self._prompt_template:\n",
    "            prefix, suffix = self._prompt_template.split(\"{review}\", 1)\n",
    "            self._prompt_prefix = prefix\n",
    "            self._prompt_suffix = suffix\n",
    "        else:\n",
    "            self._prompt_prefix = self._prompt_template\n",
    "            self._prompt_suffix = \"\"\n",
    "\n",
    "        # Pre-tokenise the prefix and suffix once for efficiency and stable budgeting\n",
    "        self._prefix_ids = self._tokenizer.encode(self._prompt_prefix, add_special_tokens=False)\n",
    "        self._suffix_ids = self._tokenizer.encode(self._prompt_suffix, add_special_tokens=False)\n",
    "\n",
    "        # Ensure the prompt scaffold alone does not exceed the model input budget\n",
    "        reserved = len(self._prefix_ids) + len(self._suffix_ids)\n",
    "        if reserved >= self._max_input_tokens:\n",
    "            raise ValueError(\n",
    "                \"Prompt is longer than MAX_INPUT_TOKENS. Reduce MAX_INPUT_TOKENS or shorten PROMPT.\"\n",
    "            )\n",
    "\n",
    "    def apply(self) -> pd.DataFrame:\n",
    "        \"\"\"Run generation for all rows and return a copy with new columns.\"\"\"\n",
    "        df_out = self._df.copy()\n",
    "\n",
    "        # Pull the text column into a plain list \n",
    "        texts = (\n",
    "            df_out[self._text_col]\n",
    "            .fillna(\"\")\n",
    "            .astype(str)\n",
    "            .tolist()\n",
    "        )\n",
    "\n",
    "        # Run batched generation + parsing\n",
    "        batch_result = self._predict(texts)\n",
    "\n",
    "        # Append outputs back onto the DataFrame\n",
    "        df_out[self._raw_output_col] = batch_result.raw_outputs\n",
    "        df_out[self._topics_col] = batch_result.extracted_topics\n",
    "\n",
    "        return df_out\n",
    "\n",
    "    def _predict(self, texts: list[str]) -> FalconBatchResult:\n",
    "        \"\"\"Generate in batches and extract numbered topics.\"\"\"\n",
    "        # Handle empty inputs\n",
    "        if not texts:\n",
    "            return FalconBatchResult(raw_outputs=[], extracted_topics=[])\n",
    "\n",
    "        # Pre-allocate output lists \n",
    "        raw_outputs: list[str] = [\"\"] * len(texts)\n",
    "        extracted_topics: list[str] = [\"\"] * len(texts)\n",
    "\n",
    "        # Determine pad token for generation; fall back to EOS if pad is unavailable\n",
    "        pad_id = getattr(self._tokenizer, \"pad_token_id\", None)\n",
    "        if pad_id is None:\n",
    "            pad_id = getattr(self._tokenizer, \"eos_token_id\", None)\n",
    "\n",
    "        # Loop over input texts in batches for speed/memory control\n",
    "        for start in range(0, len(texts), self._batch_size):\n",
    "            batch = texts[start: start + self._batch_size]\n",
    "\n",
    "            # Build prompts with per-review truncation to respect max_input_tokens\n",
    "            prompts = [self._build_prompt(t) for t in batch]\n",
    "\n",
    "            # Base generation kwargs shared for greedy and sampling modes\n",
    "            gen_kwargs: dict[str, Any] = dict(\n",
    "                max_new_tokens=self._max_new_tokens,\n",
    "                do_sample=self._do_sample,\n",
    "                pad_token_id=pad_id,\n",
    "            )\n",
    "\n",
    "            # Add sampling-specific kwargs only when enabled\n",
    "            if self._do_sample:\n",
    "                if self._temperature is not None:\n",
    "                    gen_kwargs[\"temperature\"] = self._temperature\n",
    "                if self._top_p is not None:\n",
    "                    gen_kwargs[\"top_p\"] = self._top_p\n",
    "\n",
    "            # Inference only: no gradients needed\n",
    "            with torch.inference_mode():\n",
    "                outputs = self._generator(prompts, **gen_kwargs)\n",
    "\n",
    "            # Normalise the pipeline outputs and extract three numbered topics\n",
    "            for i, out in enumerate(outputs):\n",
    "                idx = start + i\n",
    "                generated = self._normalise_pipeline_output(out)\n",
    "                raw_outputs[idx] = generated\n",
    "\n",
    "                topics = self._extract_numbered_topics(generated, n=3)\n",
    "                extracted_topics[idx] = \" | \".join(topics) if topics else \"\"\n",
    "\n",
    "        return FalconBatchResult(raw_outputs=raw_outputs, extracted_topics=extracted_topics)\n",
    "\n",
    "    def _build_prompt(self, review_text: str) -> str:\n",
    "        \"\"\"Construct a prompt with review text truncated to fit max_input_tokens.\"\"\"\n",
    "        review = str(review_text)\n",
    "\n",
    "        # Compute the token budget available for the review after accounting for prefix + suffix\n",
    "        budget = self._max_input_tokens - (len(self._prefix_ids) + len(self._suffix_ids))\n",
    "\n",
    "        # Tokenise the review without special tokens so the budget aligns with prefix/suffix tokenisation\n",
    "        review_ids = self._tokenizer.encode(review, add_special_tokens=False)\n",
    "\n",
    "        # Truncate review tokens if needed to ensure the full prompt fits within max_input_tokens\n",
    "        if len(review_ids) > budget:\n",
    "            review_ids = review_ids[:budget]\n",
    "\n",
    "        # Combine and decode back to text for the generation pipeline\n",
    "        full_ids = self._prefix_ids + review_ids + self._suffix_ids\n",
    "        return self._tokenizer.decode(full_ids, skip_special_tokens=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalise_pipeline_output(item: Any) -> str:\n",
    "        \"\"\"Normalise pipeline outputs to a single generated text string.\"\"\"\n",
    "        # HF text-generation pipeline returns:\n",
    "        # - list[dict] with key \"generated_text\"\n",
    "        # - dict with key \"generated_text\"\n",
    "        # - other string-like structures depending on wrapper/version\n",
    "        if isinstance(item, list) and item:\n",
    "            item0 = item[0]\n",
    "            if isinstance(item0, dict) and \"generated_text\" in item0:\n",
    "                return str(item0[\"generated_text\"])\n",
    "            return str(item0)\n",
    "\n",
    "        if isinstance(item, dict) and \"generated_text\" in item:\n",
    "            return str(item[\"generated_text\"])\n",
    "\n",
    "        return str(item)\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_numbered_topics(text: str, *, n: int) -> list[str]:\n",
    "        \"\"\"Extract up to n topics from numbered output (1., 2., 3.).\"\"\"\n",
    "        s = str(text)\n",
    "\n",
    "        topics: list[str] = []\n",
    "\n",
    "        # Preferred: topics appear as separate numbered lines\n",
    "        for line in s.splitlines():\n",
    "            match = re.match(r\"^\\s*([1-9])[\\.\\)]\\s*(.+?)\\s*$\", line)\n",
    "            if match:\n",
    "                topics.append(match.group(2).strip())\n",
    "            if len(topics) >= n:\n",
    "                return topics[:n]\n",
    "\n",
    "        # Fallback: topics might be inline in a single block of text\n",
    "        inline: list[str] = []\n",
    "        for m in re.finditer(r\"([1-9])[\\.\\)]\\s*(.+?)(?=\\s+[1-9][\\.\\)]\\s*|$)\", s):\n",
    "            inline.append(m.group(2).strip())\n",
    "            if len(inline) >= n:\n",
    "                break\n",
    "\n",
    "        return inline[:n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compiler = FalconDataCompiler(\n",
    "    df=df_work,\n",
    "    text_col=TEXT_COL,\n",
    "    generator=generator,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt_template=FalconParams.PROMPT,\n",
    "    batch_size=FalconParams.BATCH_SIZE,\n",
    "    max_input_tokens=FalconParams.MAX_INPUT_TOKENS,\n",
    "    max_new_tokens=FalconParams.MAX_NEW_TOKENS,\n",
    "    temperature=FalconParams.TEMPERATURE,\n",
    "    top_p=FalconParams.TOP_P,\n",
    "    do_sample=FalconParams.DO_SAMPLE,\n",
    "    raw_output_col=FalconParams.RAW_COL,\n",
    "    topics_col=FalconParams.EXTRACTED_COL,\n",
    ")\n",
    "\n",
    "df_llm = compiler.apply()\n",
    "display(df_llm[[TEXT_COL, FalconParams.RAW_COL, FalconParams.EXTRACTED_COL]].head(5))\n",
    "\n",
    "if SAVE_ARTIFACTS:\n",
    "    out_all = TABLE_DIR / \"llm_topics_negative_processed.csv\"\n",
    "    df_llm.to_csv(out_all, index=False)\n",
    "    print(\"Saved:\", out_all)\n",
    "else:\n",
    "    print(\"Sample run: skipping save of llm_topics_negative_processed.csv\")\n",
    "\n",
    "df_llm_filtered = df_llm[df_llm[FalconParams.EXTRACTED_COL].astype(str).str.strip().ne(\"\")].copy()\n",
    "print(\"Rows with extracted topics:\", len(df_llm_filtered))\n",
    "\n",
    "if SAVE_ARTIFACTS:\n",
    "    out_filtered = TABLE_DIR / \"llm_topics_negative_processed_filtered.csv\"\n",
    "    df_llm_filtered.to_csv(out_filtered, index=False)\n",
    "    print(\"Saved:\", out_filtered)\n",
    "else:\n",
    "    print(\"Sample run: skipping save of llm_topics_negative_processed_filtered.csv\")\n",
    "\n",
    "display(df_llm_filtered[[TEXT_COL, FalconParams.EXTRACTED_COL]].head(5))\n",
    "\n",
    "print(\"Tokenizer class:\", type(tokenizer).__name__)\n",
    "print(\"Is fast tokenizer:\", getattr(tokenizer, \"is_fast\", False))\n",
    "print(\"Vocab size:\", tokenizer.vocab_size)\n",
    "print(\"Model max length:\", tokenizer.model_max_length)\n",
    "print(\"Pad token:\", tokenizer.pad_token, tokenizer.pad_token_id)\n",
    "print(\"EOS token:\", tokenizer.eos_token, tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load from disk to ensure downstream steps always use saved artefacts\n",
    "TOPICS_PATH = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"TABLE_DIR\"] / \"07_topic_modelling_falcon\" / \"llm_topics_negative_processed.csv\"\n",
    "TOPICS_PATH_FILTERED = PROJECT_ROOT / CONFIG[\"OUTPUT\"][\"TABLE_DIR\"] / \"07_topic_modelling_falcon\" / \"llm_topics_negative_processed_filtered.csv\"\n",
    "\n",
    "df_llm_reloaded = load_csv(TOPICS_PATH)\n",
    "df_llm_filtered_reloaded = load_csv(TOPICS_PATH_FILTERED)\n",
    "\n",
    "df_topics_for_bertopic = df_llm_filtered_reloaded.copy()\n",
    "\n",
    "# Prepare extracted topics for BERTopic\n",
    "def normalise_llm_topics(text: str) -> str:\n",
    "    \"\"\"Normalise extracted topics into a single whitespace-separated string.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    t = text.strip()\n",
    "    if not t:\n",
    "        return \"\"\n",
    "\n",
    "    # If any numbering slipped in, remove it\n",
    "    t = re.sub(r\"(?m)^\\s*\\d+\\s*[\\.\\)\\-:]\\s*\", \"\", t)\n",
    "\n",
    "    # Convert pipe-separated topics to a single string\n",
    "    t = t.replace(\"|\", \" \")\n",
    "\n",
    "    # Normalise whitespace\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "# This is the Falcon-derived text column for modelling\n",
    "FALCON_TOPIC_TEXT_COL = \"LLM Topics Clean\"\n",
    "df_topics_for_bertopic[FALCON_TOPIC_TEXT_COL] = df_topics_for_bertopic[FalconParams.EXTRACTED_COL].apply(normalise_llm_topics)\n",
    "df_topics_for_bertopic = df_topics_for_bertopic[df_topics_for_bertopic[FALCON_TOPIC_TEXT_COL].ne(\"\")]\n",
    "\n",
    "print(\"Rows going into BERTopic (topics):\", len(df_topics_for_bertopic))\n",
    "\n",
    "STOPWORD_LANGUAGE = \"english\"\n",
    "EXTRA_STOPWORDS = [\"pure\", \"gym\", \"puregym\", # \"equipment\" retained (removing it reduced topic stability and increased fragmentation for this modelling)\n",
    "                   \"main\", \"question\", \"extracted\", \"topics\", \"review\", \"answer\" # Additional stopwords associated with generated responses from model. \n",
    "                   ] \n",
    "PUNCTUATION_PATTERN_TOPIC = r\"[-.,\\\"'’`;:!?()/&%]+\"\n",
    "USE_POS_TAGGING_TOPIC = False\n",
    "\n",
    "df_topics_for_bertopic[FALCON_TOPIC_TEXT_COL] = TextPreprocessor(\n",
    "    punctuation_pattern=PUNCTUATION_PATTERN_TOPIC,\n",
    "    extra_stopwords=EXTRA_STOPWORDS,\n",
    "    use_pos_tagging=USE_POS_TAGGING_TOPIC,\n",
    "    language=STOPWORD_LANGUAGE,\n",
    ").transform_many(df_topics_for_bertopic[FALCON_TOPIC_TEXT_COL])\n",
    "\n",
    "df_topics_for_bertopic = df_topics_for_bertopic[df_topics_for_bertopic[FALCON_TOPIC_TEXT_COL].astype(str).str.strip().ne(\"\")]\n",
    "\n",
    "display(df_topics_for_bertopic[[FalconParams.EXTRACTED_COL, FALCON_TOPIC_TEXT_COL]].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: SAMPLE_SIZE only affects Falcon extraction. BERTopic is always run on the imported (saved) full extracted topic dataset.\n",
    "#       This approach has been adopted as BERTopic struggles to find topics on small samples and creates errors when running.\n",
    "TOP_N_TOPICS = 4\n",
    "N_WORDS_BARCHART = 5\n",
    "LABEL = \"llm_topics_negative\"\n",
    "\n",
    "UMAP_N_NEIGHBOURS = 15\n",
    "UMAP_N_COMPONENTS = 5\n",
    "UMAP_MIN_DIST = 0\n",
    "UMAP_METRIC = \"cosine\"\n",
    "\n",
    "runner = BERTopicRunner(\n",
    "    model_dir=MODEL_DIR,\n",
    "    plot_dir=PLOT_DIR,\n",
    "    table_dir=TABLE_DIR,\n",
    "    seed=SEED,\n",
    "    top_n_topics=TOP_N_TOPICS,\n",
    "    n_words_barchart=N_WORDS_BARCHART,\n",
    "    min_topic_size=30,\n",
    "    show_plots=True,\n",
    "    save_png=True,\n",
    "    png_scale=2,\n",
    "    \n",
    "    \n",
    "    # UMAP controls\n",
    "    umap_n_neighbors=UMAP_N_NEIGHBOURS,\n",
    "    umap_n_components=UMAP_N_COMPONENTS,\n",
    "    umap_min_dist=UMAP_MIN_DIST,\n",
    "    umap_metric=UMAP_METRIC,\n",
    ")\n",
    "\n",
    "result_llm_topics = runner.run(\n",
    "    df_topics_for_bertopic,\n",
    "    label=LABEL,\n",
    "    text_col=FALCON_TOPIC_TEXT_COL,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(result_llm_topics.plot_paths)\n",
    "display(result_llm_topics.topic_info.head(5))\n",
    "display(result_llm_topics.top_topics_table.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "elapsed_s = time.perf_counter() - NOTEBOOK_T0\n",
    "elapsed_m = elapsed_s / 60\n",
    "print(f\"\\nTotal runtime: {elapsed_s:,.1f} seconds ({elapsed_m:,.2f} minutes)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1b3BQPwpdeenJ_MKBJavHO9yRCD6FBth3",
     "timestamp": 1725194341012
    },
    {
     "file_id": "1TR3h6zrLLaBD-hIaJVzoKaom_isIt0oD",
     "timestamp": 1724858405862
    },
    {
     "file_id": "1rwnNnduXRghHplyunqWVcyJQW5pz3nOy",
     "timestamp": 1724238923684
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "004804406af84175a09dced3a520943b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07b167d7f08d4f3abe13680e9e91454e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b8ff4e464e240d0a26ddc8d22978f33",
      "placeholder": "​",
      "style": "IPY_MODEL_4ed097c2b1be4321ab541d659b8bd478",
      "value": " 935/935 [00:00&lt;00:00, 82.2kB/s]"
     }
    },
    "0bfdf7f78113490b8d6d8946d85421d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49f5421603de482f95fd33294bbb949b",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8384dbf29a0643868cfc8ee53f8a7ba0",
      "value": 231508
     }
    },
    "13e28424f7734553b62467a2e1bb6917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1dc7deed51154716a6e0f83e382e048e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21cc2093d91f4ea8924346f7f187c39d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "222c642d2f5f4716acbc4fd0d42fc5bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_feceb8cc56cf4503af79ea961c1551c0",
       "IPY_MODEL_0bfdf7f78113490b8d6d8946d85421d1",
       "IPY_MODEL_f9a69b61eb434098aa69c7dcc5b6e887"
      ],
      "layout": "IPY_MODEL_c780f1ff9fff45bc889c4d3d99a855ff"
     }
    },
    "27d8155d54a7477aac2ca8c58d11ecfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e16a3f04851a4499bba2b30de625a510",
      "placeholder": "​",
      "style": "IPY_MODEL_13e28424f7734553b62467a2e1bb6917",
      "value": " 285/285 [00:00&lt;00:00, 24.7kB/s]"
     }
    },
    "2a92f06b672c4b38ae2117296f4bac95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "360343eaac314ede9e3b351da8a5d60a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b737fb62306546db8e6c70df474f4dca",
       "IPY_MODEL_46bf93f843e0474d9760b1242b9d274d",
       "IPY_MODEL_07b167d7f08d4f3abe13680e9e91454e"
      ],
      "layout": "IPY_MODEL_d9d2f2c58f274e3580cfe445925a921f"
     }
    },
    "3c90b7113afb4ed7ade40eb101fb0bb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46bf93f843e0474d9760b1242b9d274d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0ae937349b847e9ba1387b402e9cf58",
      "max": 935,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_beafee1481af441595e254ccb2ca21f8",
      "value": 935
     }
    },
    "48ba6828f8cb4d8cb0460e8c4d98826e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49f5421603de482f95fd33294bbb949b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ed097c2b1be4321ab541d659b8bd478": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50970208aa654b21b46443e1ea66c6bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "591b5badc54a4f0e9158723714a35d99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc6636734eb14095b92fe68522a320b6",
       "IPY_MODEL_ee35483296a945eab4d2ab4219c6de79",
       "IPY_MODEL_27d8155d54a7477aac2ca8c58d11ecfb"
      ],
      "layout": "IPY_MODEL_5adec51fb21240d5a513d87533c19804"
     }
    },
    "5adec51fb21240d5a513d87533c19804": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67dfc52cf2224a9a80013a66c6b25f50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_788161b2bb7a4b3593b5adc972f2bbe8",
      "placeholder": "​",
      "style": "IPY_MODEL_af5e9c14b0da4022a019ba095b6c3b1a",
      "value": " 466k/466k [00:00&lt;00:00, 31.3MB/s]"
     }
    },
    "6a69a20a3caa4852a99b759dc52c603c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e4dec9ef21f4dc3afe8613282f34ce8",
       "IPY_MODEL_8107133b0b524bd593e48153ca4eeb3b",
       "IPY_MODEL_9d949220d30e4c959b379831a32ba75f"
      ],
      "layout": "IPY_MODEL_941e7a71767248b79470a13ea14e99c3"
     }
    },
    "7838303da2d14668b4a5487fd3726668": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84d9ebd8c2874e4e9d058cfae56b4f76",
      "placeholder": "​",
      "style": "IPY_MODEL_3c90b7113afb4ed7ade40eb101fb0bb0",
      "value": " 438M/438M [00:27&lt;00:00, 14.3MB/s]"
     }
    },
    "788161b2bb7a4b3593b5adc972f2bbe8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ba363b7faff43a3b0adbfc281ef9137": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dc7deed51154716a6e0f83e382e048e",
      "max": 437975140,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e187b2cf690f44b595c2501d43351397",
      "value": 437975140
     }
    },
    "8107133b0b524bd593e48153ca4eeb3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba196951590c46b9ad74bf7897cdcf76",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9b9401dd276e4e32a317acb2b3ed6f54",
      "value": 112
     }
    },
    "81932317d1c145ab8e7d001fbe8a46f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8384dbf29a0643868cfc8ee53f8a7ba0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "84d9ebd8c2874e4e9d058cfae56b4f76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91beeb38d1f84f0ea44377e5078104a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce9a6259b014404d8785516cdf16ad56",
       "IPY_MODEL_a0afbe0812544ccabdca5d3f2e031a16",
       "IPY_MODEL_67dfc52cf2224a9a80013a66c6b25f50"
      ],
      "layout": "IPY_MODEL_95981efb427d4735886ea7fbab0f04de"
     }
    },
    "941e7a71767248b79470a13ea14e99c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95981efb427d4735886ea7fbab0f04de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "980ac9c2d87a43e6a565ae01ab927b72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b8ff4e464e240d0a26ddc8d22978f33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b9401dd276e4e32a317acb2b3ed6f54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d949220d30e4c959b379831a32ba75f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7296f48f9304299bd6638df79a51e6b",
      "placeholder": "​",
      "style": "IPY_MODEL_48ba6828f8cb4d8cb0460e8c4d98826e",
      "value": " 112/112 [00:00&lt;00:00, 9.82kB/s]"
     }
    },
    "9e4dec9ef21f4dc3afe8613282f34ce8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a60f3be522214308846eb44f66fd8b1b",
      "placeholder": "​",
      "style": "IPY_MODEL_b84c942040ac4af18c5c1b8da4518e45",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "a0afbe0812544ccabdca5d3f2e031a16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_980ac9c2d87a43e6a565ae01ab927b72",
      "max": 466248,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6461959823a4e5aa4e73f9384003983",
      "value": 466248
     }
    },
    "a60f3be522214308846eb44f66fd8b1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6304a3655884d909dbaed69f1c1405f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7296f48f9304299bd6638df79a51e6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a75fb509af434fc8bbed5bd44bb24514": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8507bb965a3463181a9830c98fff71e",
      "placeholder": "​",
      "style": "IPY_MODEL_a6304a3655884d909dbaed69f1c1405f",
      "value": "model.safetensors: 100%"
     }
    },
    "a8507bb965a3463181a9830c98fff71e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af5e9c14b0da4022a019ba095b6c3b1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b737fb62306546db8e6c70df474f4dca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b86427ea33c1497896595add96cc55dc",
      "placeholder": "​",
      "style": "IPY_MODEL_c51385f0704341148acd0384da57a2fa",
      "value": "config.json: 100%"
     }
    },
    "b84c942040ac4af18c5c1b8da4518e45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b86427ea33c1497896595add96cc55dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba196951590c46b9ad74bf7897cdcf76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "beafee1481af441595e254ccb2ca21f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c0ae937349b847e9ba1387b402e9cf58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c51385f0704341148acd0384da57a2fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c780f1ff9fff45bc889c4d3d99a855ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd06135c9bfc437b913008d8723b9a33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ce9a6259b014404d8785516cdf16ad56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdc3f69f26aa4007bb9b76ee297bf096",
      "placeholder": "​",
      "style": "IPY_MODEL_21cc2093d91f4ea8924346f7f187c39d",
      "value": "tokenizer.json: 100%"
     }
    },
    "d0a502c357c6429f9c2515b9d06672c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5356e37e061426882d6f62b8614eb2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9d2f2c58f274e3580cfe445925a921f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e16a3f04851a4499bba2b30de625a510": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e187b2cf690f44b595c2501d43351397": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e9fee4e0cb794d3493b7478601880a1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee35483296a945eab4d2ab4219c6de79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5356e37e061426882d6f62b8614eb2c",
      "max": 285,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd06135c9bfc437b913008d8723b9a33",
      "value": 285
     }
    },
    "ee3cf348ca0d40bfaa27bb3ada1872bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5ce90ddcdb745ee8a19a4c056122724": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a75fb509af434fc8bbed5bd44bb24514",
       "IPY_MODEL_7ba363b7faff43a3b0adbfc281ef9137",
       "IPY_MODEL_7838303da2d14668b4a5487fd3726668"
      ],
      "layout": "IPY_MODEL_d0a502c357c6429f9c2515b9d06672c1"
     }
    },
    "f6461959823a4e5aa4e73f9384003983": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f9a69b61eb434098aa69c7dcc5b6e887": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9fee4e0cb794d3493b7478601880a1b",
      "placeholder": "​",
      "style": "IPY_MODEL_2a92f06b672c4b38ae2117296f4bac95",
      "value": " 232k/232k [00:00&lt;00:00, 17.4MB/s]"
     }
    },
    "fc6636734eb14095b92fe68522a320b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_004804406af84175a09dced3a520943b",
      "placeholder": "​",
      "style": "IPY_MODEL_81932317d1c145ab8e7d001fbe8a46f4",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "fdc3f69f26aa4007bb9b76ee297bf096": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "feceb8cc56cf4503af79ea961c1551c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50970208aa654b21b46443e1ea66c6bd",
      "placeholder": "​",
      "style": "IPY_MODEL_ee3cf348ca0d40bfaa27bb3ada1872bb",
      "value": "vocab.txt: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
